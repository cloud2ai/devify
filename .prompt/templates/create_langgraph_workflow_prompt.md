# LangGraphå·¥ä½œæµç¼–æ’åˆ›å»ºæ ‡å‡†æ¨¡æ¿

è¿™æ˜¯ä¸€ä¸ªé€šç”¨çš„LangGraphå·¥ä½œæµç¼–æ’åˆ›å»ºæŒ‡å¯¼æ¨¡æ¿ï¼Œé€‚ç”¨äºä»»ä½•Django + LangGraphé¡¹ç›®ã€‚åŸºäºæœ€ä½³å®è·µå’ŒæˆåŠŸå®ç°ç»éªŒï¼Œæä¾›å®Œæ•´çš„å·¥ä½œæµç¼–æ’å¼€å‘æŒ‡å¯¼ã€‚

## ğŸ¯ é€šç”¨é…ç½®è¯´æ˜

### å ä½ç¬¦æ›¿æ¢æŒ‡å—
åœ¨ä½¿ç”¨æ­¤æ¨¡æ¿æ—¶ï¼Œè¯·å°†ä»¥ä¸‹å ä½ç¬¦æ›¿æ¢ä¸ºå®é™…å€¼ï¼š

- `[åŠŸèƒ½]` â†’ å…·ä½“åŠŸèƒ½åç§°ï¼ˆå¦‚ï¼šspeech_to_text, email_processing, data_analysisï¼‰
- `[primary_id]` â†’ ä¸»è¦å®ä½“çš„IDå‚æ•°åï¼ˆå¦‚ï¼šaudio_file_id, email_id, user_idï¼‰
- `[primary_entity]` â†’ ä¸»è¦å®ä½“çš„å˜é‡åï¼ˆå¦‚ï¼šaudio_file, email, userï¼‰
- `[PrimaryEntity]` â†’ ä¸»è¦å®ä½“çš„ç±»åï¼ˆå¦‚ï¼šAudioFile, Email, Userï¼‰
- `[YourModel]` â†’ å®é™…çš„æ•°æ®æ¨¡å‹ç±»å
- `[your_app]` â†’ å®é™…çš„Djangoåº”ç”¨åç§°
- `[StateName]` â†’ çŠ¶æ€ç±»åï¼ˆå¦‚ï¼šAudioFileState, EmailStateï¼‰
- `[workflow_name]` â†’ å·¥ä½œæµåç§°ï¼ˆå¦‚ï¼šspeech_processing_workflowï¼‰

### é¡¹ç›®é€‚é…æ£€æŸ¥æ¸…å•
- [ ] ç¡®è®¤é¡¹ç›®ä½¿ç”¨Django + LangGraphæ¶æ„
- [ ] ç¡®è®¤åŸºç¡€ç»„ä»¶å·²å®ç°ï¼ˆStateã€BaseNodeã€Checkpointï¼‰
- [ ] ç¡®è®¤æ‰€æœ‰èŠ‚ç‚¹ç±»å·²å®ç°
- [ ] ç¡®è®¤Rediså·²é…ç½®ç”¨äºcheckpointå­˜å‚¨
- [ ] ç¡®è®¤å·¥ä½œæµæ‰§è¡Œå‡½æ•°å·²å®šä¹‰

## ğŸ“ ä»£ç ç”Ÿæˆè§„èŒƒ

**é‡è¦æç¤º**ï¼šè¯·ä¸¥æ ¼éµå¾ªé¡¹ç›®ä¸­çš„Pythonä»£ç è§„èŒƒæ ‡å‡†ã€‚è¯¦ç»†è§„èŒƒè¯·å‚è€ƒï¼š`python_code_standards.md`

### å…³é”®è¦æ±‚æ‘˜è¦
- æ‰€æœ‰ä»£ç å’Œæ³¨é‡Šå¿…é¡»ä½¿ç”¨è‹±æ–‡
- ç¦æ­¢è¡Œå†…æ³¨é‡Šï¼Œæ³¨é‡Šå¿…é¡»åœ¨ä»£ç ä¸Šæ–¹
- éµå¾ªPEP 8è§„èŒƒï¼Œæ¯è¡Œä¸è¶…è¿‡79å­—ç¬¦
- ä½¿ç”¨æ­£ç¡®çš„å¯¼å…¥é¡ºåºå’Œæ–‡æ¡£å­—ç¬¦ä¸²æ ¼å¼

## ğŸ—ï¸ æ ¸å¿ƒæ¶æ„è®¾è®¡åŸåˆ™

### 1. StateGraphå®šä¹‰è®¾è®¡æ¨¡å¼

#### å·¥ä½œæµå›¾åˆ›å»ºå‡½æ•°
```python
"""
LangGraph StateGraph definition for [åŠŸèƒ½] workflow.

This module defines the complete workflow graph with proper node
connections, checkpoint management, and execution flow.
"""

import logging
from functools import lru_cache
from typing import Dict, Any

from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.redis import RedisSaver

from [your_app].agents.[åŠŸèƒ½]_state import [StateName]
from [your_app].agents.checkpoint_manager import create_checkpointer
from [your_app].agents.nodes.workflow_prepare import WorkflowPrepareNode
from [your_app].agents.nodes.[node1] import [Node1Class]
from [your_app].agents.nodes.[node2] import [Node2Class]
from [your_app].agents.nodes.[node3] import [Node3Class]
from [your_app].agents.nodes.workflow_finalize import WorkflowFinalizeNode

logger = logging.getLogger(__name__)


@lru_cache(maxsize=1)
def create_[åŠŸèƒ½]_graph():
    """
    Create and compile the [åŠŸèƒ½] processing graph.

    This function creates a StateGraph with the following structure:
    START â†’ WorkflowPrepareNode â†’ [Node1] â†’ [Node2] â†’ [Node3] â†’ WorkflowFinalizeNode â†’ END

    The graph is cached using lru_cache to avoid recreating it on each call.

    Returns:
        Compiled StateGraph ready for execution
    """
    logger.info("Creating [åŠŸèƒ½] processing graph")

    # Create the StateGraph with [StateName] as the state type
    workflow = StateGraph([StateName])

    # Add nodes to the graph
    workflow.add_node("workflow_prepare_node", WorkflowPrepareNode())
    workflow.add_node("[node1_name]", [Node1Class]())
    workflow.add_node("[node2_name]", [Node2Class]())
    workflow.add_node("[node3_name]", [Node3Class]())
    workflow.add_node("workflow_finalize_node", WorkflowFinalizeNode())

    # Define the execution flow
    workflow.add_edge(START, "workflow_prepare_node")
    workflow.add_edge("workflow_prepare_node", "[node1_name]")
    workflow.add_edge("[node1_name]", "[node2_name]")
    workflow.add_edge("[node2_name]", "[node3_name]")
    workflow.add_edge("[node3_name]", "workflow_finalize_node")
    workflow.add_edge("workflow_finalize_node", END)

    # Compile the graph with Redis checkpointer
    graph = workflow.compile(checkpointer=create_checkpointer())

    logger.info("Successfully created [åŠŸèƒ½] processing graph")
    return graph
```

### 2. å·¥ä½œæµæ‰§è¡Œå‡½æ•°è®¾è®¡æ¨¡å¼

#### ä¸»ç¼–æ’å™¨å‡½æ•°
```python
def execute_[åŠŸèƒ½]_workflow(
    [primary_id]: str,
    force: bool = False
) -> Dict[str, Any]:
    """
    Execute the complete [åŠŸèƒ½] processing workflow.

    This function orchestrates the entire [åŠŸèƒ½] processing workflow:
    1. WorkflowPrepareNode: Database pre-read + status update to PROCESSING
    2. [Node1]: [Node1åŠŸèƒ½æè¿°]
    3. [Node2]: [Node2åŠŸèƒ½æè¿°]
    4. [Node3]: [Node3åŠŸèƒ½æè¿°]
    5. WorkflowFinalizeNode: Data batch write + status update to SUCCESS/FAILED

    WORKFLOW EXECUTION FLOW
    =======================

    [å‰ä¸€æ­¥çŠ¶æ€] â†’ [WorkflowPrepareNode] â†’ [PROCESSINGçŠ¶æ€]
                        â†“
                [[Node1]] â†’ [Node1ç»“æœ]
                        â†“
                [[Node2]] â†’ [Node2ç»“æœ]
                        â†“
                [[Node3]] â†’ [Node3ç»“æœ]
                        â†“
                [WorkflowFinalizeNode] â†’ [SUCCESS/FAILEDçŠ¶æ€]

    NODE EXECUTION ORDER
    ====================

    1. WorkflowPrepareNode: Database pre-read + status update
    2. [Node1]: [Node1åŠŸèƒ½æè¿°] - [ä¾èµ–å…³ç³»è¯´æ˜]
    3. [Node2]: [Node2åŠŸèƒ½æè¿°] - [ä¾èµ–å…³ç³»è¯´æ˜]
    4. [Node3]: [Node3åŠŸèƒ½æè¿°] - [ä¾èµ–å…³ç³»è¯´æ˜]
    5. WorkflowFinalizeNode: Data batch write + status update

    Args:
        [primary_id] (str): ID of the [primary_entity] to process
        force (bool): Whether to force processing regardless of current status.
                     When True, skips status checks and allows reprocessing
                     even if the content already exists.

    Returns:
        Dict[str, Any]: Execution result containing:
            - success: bool - Whether the workflow completed successfully
            - [primary_id]: str - The processed [primary_entity] ID
            - error: str | None - Error message if failed
            - execution_time: float - Total execution time in seconds
    """
    import time
    start_time = time.time()

    try:
        # Validate that the [primary_entity] exists
        [primary_entity] = [YourModel].objects.get(id=[primary_id])
        if not [primary_entity]:
            raise Exception(
                f"[PrimaryEntity] with id {[primary_id]} not found")

        logger.info(f"[Workflow] Starting [åŠŸèƒ½] workflow for [primary_entity]: "
                    f"{[primary_id]}, force: {force}")

        # Create initial state
        initial_state = {
            "id": [primary_id],
            "user_id": [primary_entity].user_id,
            "display_name": [primary_entity].display_name,
            "file_size": [primary_entity].file_size,
            "file_md5": [primary_entity].file_md5,
            "duration": [primary_entity].duration,
            "format": [primary_entity].format,
            "storage_path": [primary_entity].storage_path,
            "storage_bucket": [primary_entity].storage_bucket,
            "sample_rate": [primary_entity].sample_rate,
            "channels": [primary_entity].channels,
            "bit_rate": [primary_entity].bit_rate,
            "asr_languages": [primary_entity].asr_languages,
            "llm_language": [primary_entity].llm_language,
            "scene": [primary_entity].scene,
            "force": force,
            "node_errors": {}
        }

        # Get the compiled graph
        graph = create_[åŠŸèƒ½]_graph()

        # Execute the workflow
        result = graph.invoke(initial_state)

        # Check final state
        if result.get("node_errors"):
            error_messages = []
            for node_name, error in result["node_errors"].items():
                error_messages.append(f"{node_name}: {error['error_message']}")

            execution_time = time.time() - start_time
            logger.error(f"[Workflow] [åŠŸèƒ½] workflow failed for {[primary_id]}: "
                        f"{'; '.join(error_messages)}")

            return {
                "success": False,
                "[primary_id]": [primary_id],
                "error": "; ".join(error_messages),
                "execution_time": execution_time
            }

        execution_time = time.time() - start_time
        logger.info(f"[Workflow] [åŠŸèƒ½] workflow completed successfully for "
                    f"{[primary_id]} in {execution_time:.2f}s")

        return {
            "success": True,
            "[primary_id]": [primary_id],
            "error": None,
            "execution_time": execution_time
        }

    except [YourModel].DoesNotExist:
        execution_time = time.time() - start_time
        logger.error(f"[Workflow] [PrimaryEntity] {[primary_id]} not found")
        return {
            "success": False,
            "[primary_id]": [primary_id],
            "error": f"[PrimaryEntity] {[primary_id]} not found",
            "execution_time": execution_time
        }
    except Exception as exc:
        execution_time = time.time() - start_time
        logger.error(f"[Workflow] Failed to execute [åŠŸèƒ½] workflow "
                     f"for {[primary_id]}: {exc}")
        return {
            "success": False,
            "[primary_id]": [primary_id],
            "error": str(exc),
            "execution_time": execution_time
        }
```

### 3. å·¥ä½œæµé…ç½®è®¾è®¡æ¨¡å¼

#### å·¥ä½œæµé…ç½®ç®¡ç†
```python
"""
Workflow configuration management for [åŠŸèƒ½] processing.

This module provides configuration management for the [åŠŸèƒ½] workflow,
including node configurations, execution parameters, and monitoring settings.
"""

import logging
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)


class [åŠŸèƒ½]WorkflowConfig:
    """
    Configuration management for [åŠŸèƒ½] workflow.

    This class provides centralized configuration management for the
    [åŠŸèƒ½] workflow, including node settings, execution parameters,
    and monitoring configurations.
    """

    def __init__(self):
        """
        Initialize the workflow configuration.
        """
        self.node_configs = {
            "workflow_prepare_node": {
                "timeout": 30,
                "retry_count": 3,
                "log_level": "INFO"
            },
            "[node1_name]": {
                "timeout": 300,
                "retry_count": 2,
                "log_level": "INFO"
            },
            "[node2_name]": {
                "timeout": 300,
                "retry_count": 2,
                "log_level": "INFO"
            },
            "[node3_name]": {
                "timeout": 300,
                "retry_count": 2,
                "log_level": "INFO"
            },
            "workflow_finalize_node": {
                "timeout": 30,
                "retry_count": 3,
                "log_level": "INFO"
            }
        }

    def get_node_config(self, node_name: str) -> Dict[str, Any]:
        """
        Get configuration for a specific node.

        Args:
            node_name: Name of the node

        Returns:
            Dictionary containing node configuration
        """
        return self.node_configs.get(node_name, {})

    def update_node_config(
        self,
        node_name: str,
        config: Dict[str, Any]
    ) -> None:
        """
        Update configuration for a specific node.

        Args:
            node_name: Name of the node
            config: New configuration dictionary
        """
        if node_name in self.node_configs:
            self.node_configs[node_name].update(config)
            logger.info(f"Updated configuration for node: {node_name}")
        else:
            logger.warning(f"Node {node_name} not found in configuration")

    def get_execution_config(self) -> Dict[str, Any]:
        """
        Get execution configuration for the workflow.

        Returns:
            Dictionary containing execution configuration
        """
        return {
            "max_execution_time": 1800,  # 30 minutes
            "checkpoint_interval": 60,   # 1 minute
            "error_retry_delay": 5,      # 5 seconds
            "monitoring_enabled": True
        }


# Global workflow configuration instance
workflow_config = [åŠŸèƒ½]WorkflowConfig()
```

## ğŸ”„ å·¥ä½œæµç¼–æ’è®¾è®¡åŸåˆ™

### 1. èŠ‚ç‚¹è¿æ¥è®¾è®¡

**æ ¸å¿ƒåŸåˆ™**ï¼š
- ä½¿ç”¨StateGraphè¿›è¡ŒèŠ‚ç‚¹ç¼–æ’
- æ˜ç¡®çš„èŠ‚ç‚¹è¿æ¥å…³ç³»
- æ”¯æŒä»ä»»æ„èŠ‚ç‚¹é‡æ–°å¼€å§‹
- ä½¿ç”¨Redis checkpointæŒä¹…åŒ–çŠ¶æ€

**èŠ‚ç‚¹è¿æ¥æ¨¡å¼**ï¼š
```python
# å®šä¹‰æ‰§è¡Œæµç¨‹
workflow.add_edge(START, "workflow_prepare_node")
workflow.add_edge("workflow_prepare_node", "[node1_name]")
workflow.add_edge("[node1_name]", "[node2_name]")
workflow.add_edge("[node2_name]", "[node3_name]")
workflow.add_edge("[node3_name]", "workflow_finalize_node")
workflow.add_edge("workflow_finalize_node", END)
```

### 2. çŠ¶æ€ç®¡ç†è®¾è®¡

**çŠ¶æ€ä¼ é€’æ¨¡å¼**ï¼š
- ä½¿ç”¨[StateName]ä½œä¸ºçŠ¶æ€ç±»å‹
- çŠ¶æ€åœ¨èŠ‚ç‚¹é—´è‡ªåŠ¨ä¼ é€’
- æ”¯æŒçŠ¶æ€æŒä¹…åŒ–å’Œæ¢å¤
- ç»Ÿä¸€çš„é”™è¯¯å¤„ç†æœºåˆ¶

**åˆå§‹çŠ¶æ€åˆ›å»º**ï¼š
```python
# åˆ›å»ºåˆå§‹çŠ¶æ€
initial_state = {
    "id": [primary_id],
    "user_id": [primary_entity].user_id,
    # ... å…¶ä»–å­—æ®µ
    "force": force,
    "node_errors": {}
}
```

### 3. æ‰§è¡Œæµç¨‹è®¾è®¡

**æ‰§è¡Œæµç¨‹æ¨¡å¼**ï¼š
1. **WorkflowPrepareNode**ï¼šæ•°æ®åº“é¢„è¯»å– + çŠ¶æ€æ›´æ–°
2. **ä¸­é—´èŠ‚ç‚¹**ï¼šçº¯Stateæ“ä½œï¼Œæ— æ•°æ®åº“äº¤äº’
3. **WorkflowFinalizeNode**ï¼šæ•°æ®æ‰¹é‡å†™å…¥ + çŠ¶æ€æ›´æ–°

**Forceæ”¯æŒ**ï¼š
- é€šè¿‡Stateä¼ é€’forceæ ‡å¿—
- é¦–å°¾èŠ‚ç‚¹å¤„ç†forceçŠ¶æ€
- ä¸­é—´èŠ‚ç‚¹ä¸“æ³¨ä¸šåŠ¡é€»è¾‘

## ğŸ“ æ—¥å¿—è¾“å‡ºæ ‡å‡†åŒ–

### 1. ç»Ÿä¸€æ—¥å¿—æ ‡ç­¾
```python
# ä½¿ç”¨ [Workflow] ä½œä¸ºç»Ÿä¸€æ ‡ç­¾
logger.info(f"[Workflow] Starting [åŠŸèƒ½] workflow for [primary_entity]: "
            f"{[primary_id]}, force: {force}")

logger.info(f"[Workflow] [åŠŸèƒ½] workflow completed successfully for "
            f"{[primary_id]} in {execution_time:.2f}s")

logger.error(f"[Workflow] [åŠŸèƒ½] workflow failed for {[primary_id]}: "
            f"{error_message}")
```

### 2. è¡Œé•¿åº¦æ§åˆ¶ï¼ˆâ‰¤79å­—ç¬¦ï¼‰
```python
# æ­£ç¡®çš„åˆ†è¡Œæ–¹å¼
logger.info(f"[Workflow] Starting [åŠŸèƒ½] workflow for [primary_entity]: "
            f"{[primary_id]}, force: {force}")

# åœ¨é€»è¾‘æ–­ç‚¹å¤„åˆ†è¡Œï¼Œä¿æŒè¯­ä¹‰å®Œæ•´
logger.info(f"[Workflow] [åŠŸèƒ½] workflow completed successfully for "
            f"{[primary_id]} in {execution_time:.2f}s")
```

### 3. æ—¥å¿—çº§åˆ«ä½¿ç”¨
- **info**: æ­£å¸¸æµç¨‹èŠ‚ç‚¹å’Œé‡è¦çŠ¶æ€å˜åŒ–
- **error**: é”™è¯¯æƒ…å†µå’Œå¼‚å¸¸å¤„ç†
- **debug**: è¯¦ç»†çš„æ‰§è¡Œä¿¡æ¯å’Œé…ç½®ä¿¡æ¯

## ğŸ”§ å·¥ä½œæµç¼–æ’æœ€ä½³å®è·µ

### 1. å›¾åˆ›å»ºæœ€ä½³å®è·µ
```python
# ä½¿ç”¨lru_cacheç¼“å­˜ç¼–è¯‘åçš„å›¾
@lru_cache(maxsize=1)
def create_[åŠŸèƒ½]_graph():
    workflow = StateGraph([StateName])
    # ... æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
    return workflow.compile(checkpointer=create_checkpointer())
```

### 2. èŠ‚ç‚¹è¿æ¥æœ€ä½³å®è·µ
```python
# æ˜ç¡®çš„èŠ‚ç‚¹è¿æ¥å…³ç³»
workflow.add_edge(START, "workflow_prepare_node")
workflow.add_edge("workflow_prepare_node", "[node1_name]")
# ... å…¶ä»–è¿æ¥
workflow.add_edge("workflow_finalize_node", END)
```

### 3. çŠ¶æ€ç®¡ç†æœ€ä½³å®è·µ
```python
# åˆ›å»ºå®Œæ•´çš„åˆå§‹çŠ¶æ€
initial_state = {
    "id": [primary_id],
    "user_id": [primary_entity].user_id,
    # ... æ‰€æœ‰å¿…è¦å­—æ®µ
    "force": force,
    "node_errors": {}
}
```

## ğŸ›¡ï¸ é”™è¯¯å¤„ç†æ¨¡å¼

### 1. å·¥ä½œæµé”™è¯¯å¤„ç†
```python
try:
    # å·¥ä½œæµæ‰§è¡Œ
    result = graph.invoke(initial_state)

    # æ£€æŸ¥æœ€ç»ˆçŠ¶æ€
    if result.get("node_errors"):
        # å¤„ç†èŠ‚ç‚¹é”™è¯¯
        pass

except Exception as exc:
    # å¤„ç†æ‰§è¡Œé”™è¯¯
    logger.error(f"[Workflow] Failed to execute [åŠŸèƒ½] workflow: {exc}")
```

### 2. èŠ‚ç‚¹é”™è¯¯æ£€æŸ¥
```python
# æ£€æŸ¥èŠ‚ç‚¹é”™è¯¯
if result.get("node_errors"):
    error_messages = []
    for node_name, error in result["node_errors"].items():
        error_messages.append(f"{node_name}: {error['error_message']}")

    return {
        "success": False,
        "error": "; ".join(error_messages)
    }
```

### 3. å®ä½“éªŒè¯é”™è¯¯å¤„ç†
```python
try:
    [primary_entity] = [YourModel].objects.get(id=[primary_id])
    if not [primary_entity]:
        raise Exception(f"[PrimaryEntity] with id {[primary_id]} not found")
except [YourModel].DoesNotExist:
    logger.error(f"[Workflow] [PrimaryEntity] {[primary_id]} not found")
    return {"success": False, "error": f"[PrimaryEntity] {[primary_id]} not found"}
```

## ğŸ“Š è°ƒè¯•å’Œç›‘æ§æ”¯æŒ

### 1. å·¥ä½œæµæ‰§è¡Œç›‘æ§
```python
# è®°å½•æ‰§è¡Œæ—¶é—´
start_time = time.time()
# ... æ‰§è¡Œå·¥ä½œæµ
execution_time = time.time() - start_time

logger.info(f"[Workflow] [åŠŸèƒ½] workflow completed successfully for "
            f"{[primary_id]} in {execution_time:.2f}s")
```

### 2. èŠ‚ç‚¹æ‰§è¡Œç›‘æ§
```python
# è®°å½•èŠ‚ç‚¹æ‰§è¡Œä¿¡æ¯
logger.info(f"[Workflow] Starting [åŠŸèƒ½] workflow for [primary_entity]: "
            f"{[primary_id]}, force: {force}")
```

### 3. é”™è¯¯ç›‘æ§
```python
# è®°å½•é”™è¯¯ä¿¡æ¯
logger.error(f"[Workflow] [åŠŸèƒ½] workflow failed for {[primary_id]}: "
            f"{error_message}")
```

## ğŸ“‹ å…·ä½“å®ç°æ£€æŸ¥æ¸…å•

### âœ… å¿…é¡»å®ç°çš„ç»“æ„
- [ ] æ­£ç¡®çš„StateGraphå®šä¹‰
- [ ] æ­£ç¡®çš„èŠ‚ç‚¹è¿æ¥å…³ç³»
- [ ] æ­£ç¡®çš„å·¥ä½œæµæ‰§è¡Œå‡½æ•°
- [ ] æ­£ç¡®çš„é…ç½®ç®¡ç†
- [ ] å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²

### âœ… å›¾åˆ›å»ºæ£€æŸ¥
- [ ] ä½¿ç”¨lru_cacheç¼“å­˜ç¼–è¯‘åçš„å›¾
- [ ] æ­£ç¡®çš„èŠ‚ç‚¹æ·»åŠ é¡ºåº
- [ ] æ­£ç¡®çš„è¾¹è¿æ¥å…³ç³»
- [ ] æ­£ç¡®çš„checkpointeré…ç½®

### âœ… å·¥ä½œæµæ‰§è¡Œæ£€æŸ¥
- [ ] æ­£ç¡®çš„åˆå§‹çŠ¶æ€åˆ›å»º
- [ ] æ­£ç¡®çš„å®ä½“éªŒè¯
- [ ] æ­£ç¡®çš„é”™è¯¯å¤„ç†
- [ ] æ­£ç¡®çš„æ‰§è¡Œç»“æœæ£€æŸ¥

### âœ… æ—¥å¿—æ ‡å‡†åŒ–æ£€æŸ¥
- [ ] æ‰€æœ‰loggerä½¿ç”¨[Workflow]æ ‡ç­¾
- [ ] æ¯è¡Œloggerè¾“å‡ºâ‰¤79å­—ç¬¦
- [ ] åœ¨é€»è¾‘æ–­ç‚¹å¤„åˆç†åˆ†è¡Œ
- [ ] ä¿æŒè¯­ä¹‰å®Œæ•´æ€§

### âœ… ä»£ç è§„èŒƒæ£€æŸ¥
- [ ] æ‰€æœ‰ä»£ç ä½¿ç”¨è‹±æ–‡
- [ ] æ‰€æœ‰æ³¨é‡Šä½¿ç”¨è‹±æ–‡
- [ ] ç¦æ­¢è¡Œå†…æ³¨é‡Š
- [ ] éµå¾ªPEP 8è§„èŒƒ
- [ ] æ¯è¡Œä¸è¶…è¿‡79å­—ç¬¦

## ğŸ¯ å…³é”®å®ç°ç»†èŠ‚

### 1. å›¾åˆ›å»ºæ¨¡å¼
```python
# ä½¿ç”¨lru_cacheç¼“å­˜ç¼–è¯‘åçš„å›¾
@lru_cache(maxsize=1)
def create_[åŠŸèƒ½]_graph():
    workflow = StateGraph([StateName])
    # ... æ·»åŠ èŠ‚ç‚¹å’Œè¾¹
    return workflow.compile(checkpointer=create_checkpointer())
```

### 2. èŠ‚ç‚¹è¿æ¥æ¨¡å¼
```python
# æ˜ç¡®çš„èŠ‚ç‚¹è¿æ¥å…³ç³»
workflow.add_edge(START, "workflow_prepare_node")
workflow.add_edge("workflow_prepare_node", "[node1_name]")
# ... å…¶ä»–è¿æ¥
workflow.add_edge("workflow_finalize_node", END)
```

### 3. çŠ¶æ€ç®¡ç†æ¨¡å¼
```python
# åˆ›å»ºå®Œæ•´çš„åˆå§‹çŠ¶æ€
initial_state = {
    "id": [primary_id],
    "user_id": [primary_entity].user_id,
    # ... æ‰€æœ‰å¿…è¦å­—æ®µ
    "force": force,
    "node_errors": {}
}
```

## ğŸš¨ å¸¸è§é™·é˜±å’Œé¿å…æ–¹æ³•

### âŒ é¿å…çš„åæ¨¡å¼
1. **ç¼ºå°‘å›¾ç¼“å­˜** - åº”è¯¥ä½¿ç”¨lru_cacheç¼“å­˜ç¼–è¯‘åçš„å›¾
2. **ç¼ºå°‘å®ä½“éªŒè¯** - åº”è¯¥éªŒè¯[primary_entity]å­˜åœ¨
3. **ç¡¬ç¼–ç æ—¥å¿—æ ‡ç­¾** - åº”è¯¥ä½¿ç”¨[Workflow]
4. **ç¼ºå°‘é”™è¯¯æ£€æŸ¥** - åº”è¯¥æ£€æŸ¥æœ€ç»ˆçŠ¶æ€ä¸­çš„é”™è¯¯
5. **ä½¿ç”¨è¡Œå†…æ³¨é‡Š** - åº”è¯¥å°†æ³¨é‡Šæ”¾åœ¨ä»£ç ä¸Šæ–¹
6. **ä½¿ç”¨ä¸­æ–‡æ³¨é‡Š** - æ‰€æœ‰æ³¨é‡Šå¿…é¡»ä½¿ç”¨è‹±æ–‡

### âœ… æ¨èçš„æœ€ä½³å®è·µ
1. **ä½¿ç”¨lru_cache** - é¿å…é‡å¤ç¼–è¯‘å›¾
2. **å®Œæ•´çš„æ–‡æ¡£å­—ç¬¦ä¸²** - åŒ…å«å·¥ä½œæµå’Œæ‰§è¡Œé¡ºåº
3. **æ¸…æ™°çš„èŠ‚ç‚¹è¿æ¥** - æ¯ä¸ªè¿æ¥éƒ½æœ‰æ˜ç¡®çš„ç›®çš„
4. **ç»Ÿä¸€çš„æ—¥å¿—æ ¼å¼** - ä¾¿äºç›‘æ§å’Œè°ƒè¯•
5. **é€‚å½“çš„é”™è¯¯å¤„ç†** - ç¡®ä¿å¼‚å¸¸æ­£ç¡®ä¼ æ’­
6. **è‹±æ–‡ä»£ç å’Œæ³¨é‡Š** - ä¿æŒä»£ç å›½é™…åŒ–
7. **éµå¾ªPEP 8è§„èŒƒ** - ä¿æŒä»£ç ä¸€è‡´æ€§

## ğŸ“ ä½¿ç”¨æŒ‡å—

### å¿«é€Ÿå¼€å§‹
1. **å¤åˆ¶æ­¤æ¨¡æ¿**ä½œä¸ºå·¥ä½œæµç¼–æ’çš„èµ·å§‹ç‚¹
2. **æ›¿æ¢å ä½ç¬¦**ï¼šæ ¹æ®å ä½ç¬¦æ›¿æ¢æŒ‡å—æ›´æ–°æ‰€æœ‰å ä½ç¬¦
3. **è°ƒæ•´èŠ‚ç‚¹è¿æ¥**ï¼šæ ¹æ®å…·ä½“éœ€æ±‚ä¿®æ”¹èŠ‚ç‚¹è¿æ¥å…³ç³»
4. **æ›´æ–°å·¥ä½œæµæ‰§è¡Œ**ï¼šæ ¹æ®å®é™…éœ€æ±‚ä¿®æ”¹æ‰§è¡Œé€»è¾‘
5. **æµ‹è¯•å·¥ä½œæµ**ï¼šç¡®ä¿å·¥ä½œæµèƒ½æ­£ç¡®æ‰§è¡Œå’Œä¼ é€’çŠ¶æ€
6. **éªŒè¯æ—¥å¿—æ ¼å¼**ï¼šç¡®ä¿æ‰€æœ‰æ—¥å¿—ä½¿ç”¨[Workflow]ä¸”â‰¤79å­—ç¬¦

### å¸¸è§ä½¿ç”¨åœºæ™¯
- **è¯­éŸ³å¤„ç†å·¥ä½œæµ**ï¼šè¯­éŸ³è¯†åˆ« â†’ åˆ†æ®µå¤„ç† â†’ æ€»ç»“ç”Ÿæˆ
- **é‚®ä»¶å¤„ç†å·¥ä½œæµ**ï¼šé‚®ä»¶è§£æ â†’ å†…å®¹åˆ†æ â†’ æ€»ç»“ç”Ÿæˆ
- **æ•°æ®åˆ†æå·¥ä½œæµ**ï¼šæ•°æ®æ¸…æ´— â†’ æ•°æ®è½¬æ¢ â†’ ç»“æœç”Ÿæˆ
- **æ–‡ä»¶å¤„ç†å·¥ä½œæµ**ï¼šæ–‡ä»¶ä¸Šä¼  â†’ æ ¼å¼è½¬æ¢ â†’ ç»“æœå­˜å‚¨

### é«˜çº§é…ç½®é€‰é¡¹
- **æ¡ä»¶æ‰§è¡Œ**ï¼šæ ¹æ®å‚æ•°å†³å®šæ˜¯å¦æ‰§è¡ŒæŸäº›èŠ‚ç‚¹
- **å¹¶è¡Œå¤„ç†**ï¼šä½¿ç”¨å¹¶è¡ŒèŠ‚ç‚¹å®ç°å¹¶è¡Œå¤„ç†
- **é”™è¯¯é‡è¯•**ï¼šé…ç½®èŠ‚ç‚¹é‡è¯•ç­–ç•¥å’Œé”™è¯¯å¤„ç†
- **ç›‘æ§é›†æˆ**ï¼šæ·»åŠ å·¥ä½œæµæ‰§è¡Œç›‘æ§å’Œå‘Šè­¦
- **æ€§èƒ½ä¼˜åŒ–**ï¼šä½¿ç”¨ç¼“å­˜å’Œæ‰¹é‡æ“ä½œä¼˜åŒ–æ€§èƒ½

è¿™ä¸ªæ¨¡æ¿åŸºäºLangGraphæœ€ä½³å®è·µå’ŒæˆåŠŸå®ç°ç»éªŒï¼ŒåŒ…å«äº†æ‰€æœ‰å…³é”®çš„å·¥ä½œæµç¼–æ’è®¾è®¡æ¨¡å¼å’Œå®ç°ç»†èŠ‚ï¼Œé€‚ç”¨äºä»»ä½•Django + LangGraphé¡¹ç›®ã€‚
