# Celery to LangGraph Refactoring - Design Document

## æ¦‚è¿°

æœ¬è®¾è®¡æ–‡æ¡£æè¿°äº†å°†ç°æœ‰ Celery task chain æ¶æ„é‡æ„ä¸º LangGraph æ¶æ„çš„è¯¦ç»†æŠ€æœ¯è®¾è®¡ã€‚é‡æ„å›´ç»•ä¸‰ä¸ªæ ¸å¿ƒä»·å€¼å±•å¼€ï¼š

### æ ¸å¿ƒä»·å€¼

1. **ç®€åŒ–çŠ¶æ€æœºï¼Œæé«˜å¯æ‰©å±•æ€§**
   - ä»å¤æ‚çš„å¤šçŠ¶æ€æœºåˆ¶ç®€åŒ–ä¸ºæ ¸å¿ƒçŠ¶æ€ï¼ˆPROCESSING, SUCCESS, FAILEDï¼‰
   - ä½¿ç”¨ LangGraph State ç®¡ç†ä¸­é—´å¤„ç†çŠ¶æ€
   - é™ä½çŠ¶æ€æœºç»´æŠ¤æˆæœ¬ï¼Œæé«˜ç³»ç»Ÿå¯æ‰©å±•æ€§

2. **æ•°æ®åº“æ“ä½œä¸ State è§£è€¦**
   - é‡‡ç”¨"é¦–å°¾æ•°æ®åº“æ“ä½œï¼Œä¸­é—´çº¯ State æ“ä½œ"çš„è®¾è®¡æ¨¡å¼
   - èŒè´£åˆ†ç¦»ï¼šæ•°æ®æŒä¹…åŒ–ä¸ä¸šåŠ¡é€»è¾‘åˆ†ç¦»
   - é¿å…æ•°æ®åº“çŠ¶æ€æœºå’Œ LangGraph çŠ¶æ€çš„äº¤å‰è€¦åˆ

3. **ç»Ÿä¸€å·¥ä½œæµç¼–æ’è°ƒåº¦**
   - ä½¿ç”¨ LangGraph StateGraph æ›¿ä»£ Celery chain
   - Redis checkpoint æœºåˆ¶ç¡®ä¿çŠ¶æ€æŒä¹…åŒ–
   - æ”¯æŒä»ä»»æ„èŠ‚ç‚¹æ¢å¤æ‰§è¡Œï¼Œå¢å¼ºç³»ç»Ÿå¯é æ€§

4. **å¹¶å‘æ‰§è¡Œï¼Œæå‡æ€§èƒ½**
   - LangGraph åŸç”Ÿæ”¯æŒèŠ‚ç‚¹å¹¶å‘æ‰§è¡Œ
   - ç‹¬ç«‹ä¸šåŠ¡é€»è¾‘å¯å¹¶è¡Œå¤„ç†ï¼ˆå¦‚ OCR å’Œé‚®ä»¶å†…å®¹å¤„ç†ï¼‰
   - æ˜¾è‘—é™ä½å·¥ä½œæµæ€»æ‰§è¡Œæ—¶é—´ï¼ˆé¢„è®¡æå‡ 30-40%ï¼‰

### è®¾è®¡ç†å¿µ

**ä» Celery åˆ° LangGraph çš„æ¶æ„æ¼”è¿›**ï¼š

```mermaid
graph TD
    subgraph "Celery Architecture (Before)"
        A1[Task 1] --> A2[Task 2]
        A2 --> A3[Task 3]
        A3 --> A4[Task 4]
        A1 -.-> DB1[(Database)]
        A2 -.-> DB1
        A3 -.-> DB1
        A4 -.-> DB1
        ST1[13+ States]
    end

    subgraph "LangGraph Architecture (After)"
        B1[Prepare Node] --> B2[Business Node 1]
        B2 --> B3[Business Node 2]
        B3 --> B4[Business Node 3]
        B4 --> B5[Finalize Node]
        B1 -.-> DB2[(Database)]
        B5 -.-> DB2
        B2 --> ST2[LangGraph State]
        B3 --> ST2
        B4 --> ST2
        ST3[6 Core States]
        CH[Redis Checkpoint]
    end

    style A1 fill:#ffcccc
    style A2 fill:#ffcccc
    style A3 fill:#ffcccc
    style A4 fill:#ffcccc
    style B1 fill:#ff9999
    style B5 fill:#ff9999
    style B2 fill:#99ff99
    style B3 fill:#99ff99
    style B4 fill:#99ff99
```

**å…³é”®æ”¹è¿›**ï¼š
- ğŸ”´ çº¢è‰²èŠ‚ç‚¹ï¼šæ•°æ®åº“æ“ä½œèŠ‚ç‚¹ï¼ˆé¦–å°¾èŠ‚ç‚¹ï¼‰
- ğŸŸ¢ ç»¿è‰²èŠ‚ç‚¹ï¼šçº¯ State æ“ä½œèŠ‚ç‚¹ï¼ˆä¸šåŠ¡èŠ‚ç‚¹ï¼‰
- æ•°æ®åº“è®¿é—®ä»åˆ†æ•£åœ¨å„ä¸ªä»»åŠ¡ï¼Œé›†ä¸­åˆ°é¦–å°¾ä¸¤ä¸ªèŠ‚ç‚¹
- çŠ¶æ€ç®¡ç†ä»å¤æ‚çš„æ•°æ®åº“çŠ¶æ€æœºï¼Œç®€åŒ–ä¸º LangGraph State ç®¡ç†

## æ¶æ„è®¾è®¡

### ç³»ç»Ÿæ¶æ„

```mermaid
graph TB
    subgraph "Existing Entry Points (Unchanged)"
        API[REST API / Views]
        ADMIN[Admin Actions]
        SCHED[Schedulers]
    end

    subgraph "Task Layer (Refactoring Target)"
        CELERY[Celery Task Wrapper]
        WF[LangGraph Workflow Orchestrator]
        CELERY --> WF
    end

    subgraph "LangGraph Workflow Layer"
        WF --> GP[StateGraph]
        GP --> P[Prepare Node]
        GP --> BN1[Business Node 1]
        GP --> BN2[Business Node 2]
        GP --> BN3[Business Node N]
        GP --> F[Finalize Node]
    end

    subgraph "State Management Layer"
        STATE[LangGraph State]
        STATE --> SH[State Helper Functions]
        STATE --> ERR[Error Tracking]
    end

    subgraph "Persistence Layer"
        CP[Checkpoint Manager]
        CP --> REDIS[(Redis Storage)]
        DB[(Django Database)]
    end

    API --> CELERY
    ADMIN --> CELERY
    SCHED --> CELERY

    P --> DB
    F --> DB
    P --> STATE
    BN1 --> STATE
    BN2 --> STATE
    BN3 --> STATE
    F --> STATE

    WF --> CP
    GP --> CP

    style CELERY fill:#ffffcc
    style WF fill:#ffffcc
    style P fill:#ff9999
    style F fill:#ff9999
    style BN1 fill:#99ff99
    style BN2 fill:#99ff99
    style BN3 fill:#99ff99
```

**è¯´æ˜**ï¼šğŸŸ¡ é»„è‰²éƒ¨åˆ†æ˜¯æœ¬æ¬¡é‡æ„çš„ç›®æ ‡åŒºåŸŸï¼ˆä»»åŠ¡å±‚ï¼‰ï¼Œå…¶ä»–å…¥å£ç‚¹ä¿æŒä¸å˜ã€‚

### å±‚çº§èŒè´£

#### 1. ç°æœ‰å…¥å£ç‚¹å±‚ï¼ˆä¿æŒä¸å˜ï¼‰
- **REST API / Views**ï¼šç°æœ‰çš„ API æ¥å£ç»§ç»­è°ƒç”¨ Celery ä»»åŠ¡
- **Admin Actions**ï¼šç°æœ‰çš„ç®¡ç†åå°æ“ä½œç»§ç»­è°ƒç”¨ Celery ä»»åŠ¡
- **Schedulers**ï¼šç°æœ‰çš„å®šæ—¶ä»»åŠ¡ç»§ç»­è°ƒç”¨ Celery ä»»åŠ¡
- è¿™äº›å…¥å£ç‚¹**ä¸éœ€è¦ä¿®æ”¹**ï¼Œå› ä¸º Celery ä»»åŠ¡æ¥å£ä¿æŒå…¼å®¹

#### 2. ä»»åŠ¡å±‚ï¼ˆé‡æ„ç›®æ ‡ï¼‰
- **Celery ä»»åŠ¡åŒ…è£…å™¨**ï¼šæä¾›å‘åå…¼å®¹çš„æ¥å£
  - ä¿æŒåŸæœ‰çš„ä»»åŠ¡ç­¾å `process_[feature]_task(entity_id, force)`
  - å†…éƒ¨è°ƒç”¨ LangGraph å·¥ä½œæµæ‰§è¡Œå™¨
  - å¯é€‰ï¼šæ·»åŠ å¼ƒç”¨è­¦å‘Š
- **LangGraph å·¥ä½œæµç¼–æ’å™¨**ï¼šæ–°çš„å·¥ä½œæµæ‰§è¡Œå™¨
  - `execute_[feature]_workflow()`ï¼šå·¥ä½œæµæ‰§è¡Œå…¥å£
  - åˆ›å»ºåˆå§‹çŠ¶æ€
  - é…ç½®æ£€æŸ¥ç‚¹å‚æ•°
  - è°ƒç”¨çŠ¶æ€å›¾

#### 3. LangGraph å·¥ä½œæµå±‚ï¼ˆæ–°å®ç°ï¼‰
- **çŠ¶æ€å›¾ï¼ˆStateGraphï¼‰**ï¼šLangGraph çš„æ ¸å¿ƒçŠ¶æ€å›¾
  - `create_[feature]_graph()`ï¼šåˆ›å»ºå¹¶ç¼–è¯‘çŠ¶æ€å›¾
  - å®šä¹‰èŠ‚ç‚¹å’Œè¾¹ï¼ˆä¾èµ–å…³ç³»ï¼‰
  - é…ç½® Redis æ£€æŸ¥ç‚¹ç®¡ç†å™¨
  - ç®¡ç†èŠ‚ç‚¹æ‰§è¡Œé¡ºåº
- **å·¥ä½œæµèŠ‚ç‚¹**ï¼šå®é™…æ‰§è¡Œé€»è¾‘çš„èŠ‚ç‚¹
  - å‡†å¤‡èŠ‚ç‚¹ï¼šæ•°æ®åº“è¯»å–å’ŒçŠ¶æ€åˆå§‹åŒ–
  - ä¸šåŠ¡èŠ‚ç‚¹ï¼šä¸šåŠ¡é€»è¾‘å¤„ç†
  - å®ŒæˆèŠ‚ç‚¹ï¼šç»“æœåŒæ­¥å’ŒçŠ¶æ€æ›´æ–°

#### 4. çŠ¶æ€ç®¡ç†å±‚ï¼ˆæ–°å®ç°ï¼‰
- **LangGraph çŠ¶æ€**ï¼šä½¿ç”¨ TypedDict å®šä¹‰çš„çŠ¶æ€ç»“æ„
  - æ ¸å¿ƒå­—æ®µï¼šä» Django æ¨¡å‹æ˜ å°„çš„æ•°æ®å­—æ®µ
  - ç»“æœå­—æ®µï¼šå·¥ä½œæµäº§ç”Ÿçš„ä¸­é—´å’Œæœ€ç»ˆç»“æœ
  - å›ºå®šå­—æ®µï¼šé”™è¯¯æ¶ˆæ¯ã€èŠ‚ç‚¹é”™è¯¯ã€å¼ºåˆ¶æ ‡å¿—
- **çŠ¶æ€è¾…åŠ©å‡½æ•°**ï¼šçŠ¶æ€æ“ä½œè¾…åŠ©å‡½æ•°
  - `add_node_error()`ï¼šæ·»åŠ èŠ‚ç‚¹é”™è¯¯
  - `has_node_errors()`ï¼šæ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
  - `get_node_errors_by_name()`ï¼šè·å–ç‰¹å®šèŠ‚ç‚¹çš„é”™è¯¯

#### 5. æŒä¹…åŒ–å±‚ï¼ˆéƒ¨åˆ†æ–°å®ç°ï¼‰
- **æ£€æŸ¥ç‚¹ç®¡ç†å™¨**ï¼ˆæ–°å¢ï¼‰ï¼šç®¡ç† Redis æ£€æŸ¥ç‚¹
  - åˆ›å»ºå’Œé…ç½® Redis æ£€æŸ¥ç‚¹ç®¡ç†å™¨
  - ç®¡ç†æ£€æŸ¥ç‚¹ç”Ÿå‘½å‘¨æœŸ
  - æä¾›æ£€æŸ¥ç‚¹æŸ¥è¯¢æ¥å£
- **Django æ•°æ®åº“**ï¼ˆå·²æœ‰ï¼‰ï¼šæŒä¹…åŒ–ä¸šåŠ¡æ•°æ®
  - å­˜å‚¨å®ä½“æ•°æ®ï¼ˆå¦‚ AudioFileã€EmailMessageï¼‰
  - å­˜å‚¨æœ€ç»ˆå¤„ç†ç»“æœ
  - ç®¡ç†ç®€åŒ–åçš„çŠ¶æ€æœº

### æ•°æ®æµæ¶æ„

```mermaid
sequenceDiagram
    participant Entry as Entry Point<br/>(API/Admin/Scheduler)
    participant Celery as Celery Task<br/>(Wrapper)
    participant Graph as LangGraph<br/>StateGraph Engine
    participant Prep as Prepare Node
    participant BN as Business Nodes
    participant Fin as Finalize Node
    participant DB as Database

    Note over Entry,DB: External caller â†’ Task wrapper â†’ LangGraph execution

    Entry->>Celery: Call existing task interface
    Celery->>Graph: execute_workflow(entity_id, force)

    Note over Graph: Create initial State<br/>Configure checkpoint

    Graph->>Prep: invoke with State
    Prep->>DB: Read entity data
    Prep->>DB: Update status to PROCESSING
    Note over Prep: Populate State with<br/>entity data
    Prep-->>Graph: Return updated State

    Note over Graph: Auto save checkpoint to Redis

    loop For each business node
        Graph->>BN: invoke with State
        Note over BN: Read from State<br/>Execute business logic<br/>Write results to State
        BN-->>Graph: Return updated State
        Note over Graph: Auto save checkpoint to Redis
    end

    Graph->>Fin: invoke with State

    alt No errors in State
        Fin->>DB: Batch write results (atomic)
        Fin->>DB: Update status to SUCCESS
    else Has errors in State
        Fin->>DB: Update status to FAILED
    end

    Fin-->>Graph: Return final State
    Graph-->>Celery: Return execution result
    Celery-->>Entry: Return task result
```

**å…³é”®è¯´æ˜**ï¼š
- ğŸŸ¢ **å…¥å£ç‚¹å±‚**ï¼ˆAPI/Admin/Schedulerï¼‰**ä¸éœ€è¦ä¿®æ”¹**
- ğŸŸ¡ **Celery ä»»åŠ¡å±‚**æä¾›å…¼å®¹æ€§åŒ…è£…ï¼Œä¿æŒåŸæœ‰æ¥å£
- ğŸ”µ **LangGraph å¼•æ“**è‡ªåŠ¨ç®¡ç†çŠ¶æ€ä¼ é€’å’Œæ£€æŸ¥ç‚¹æŒä¹…åŒ–
- ğŸ”´ **æ•°æ®åº“æ“ä½œ**ä»…åœ¨é¦–å°¾èŠ‚ç‚¹ï¼ˆå‡†å¤‡èŠ‚ç‚¹å’Œå®ŒæˆèŠ‚ç‚¹ï¼‰
- **çŠ¶æ€**æ˜¯æ•°æ®ç»“æ„ï¼Œåœ¨èŠ‚ç‚¹é—´ä¼ é€’ï¼ˆä¸ä½œä¸ºå•ç‹¬å‚ä¸è€…ï¼‰
- **æ£€æŸ¥ç‚¹**ç”± LangGraph è‡ªåŠ¨ç®¡ç†ï¼ˆä¸ä½œä¸ºå•ç‹¬å‚ä¸è€…ï¼‰

### èŠ‚ç‚¹æ¶æ„æ¨¡å¼

#### åŸºç¡€èŠ‚ç‚¹ç±»

æ‰€æœ‰èŠ‚ç‚¹ç»§æ‰¿è‡ª `BaseLangGraphNode`ï¼Œæä¾›ç»Ÿä¸€çš„æ¥å£å’Œé”™è¯¯å¤„ç†ï¼š

```python
class BaseLangGraphNode(ABC):
    """
    Base class for all LangGraph nodes.

    Provides:
    - Unified error handling
    - Node entry condition checking
    - Lifecycle hooks (before/after processing)
    - Logging infrastructure
    """

    def __call__(self, state: StateType) -> StateType:
        """Main entry point - orchestrates lifecycle"""

    def can_enter_node(self, state: StateType) -> bool:
        """Check if node can be entered"""

    def before_processing(self, state: StateType) -> StateType:
        """Pre-processing hook"""

    @abstractmethod
    def execute_processing(self, state: StateType) -> StateType:
        """Core business logic - must be implemented"""

    def after_processing(self, state: StateType) -> StateType:
        """Post-processing hook"""

    def _handle_error(self, error: Exception, state: StateType) -> StateType:
        """Error handling"""
```

#### Node Types and Responsibilities

**1. Prepare Node (é¦–èŠ‚ç‚¹)**

```mermaid
graph LR
    A[Enter Prepare Node] --> B{Force Mode?}
    B -->|No| C[Check Status]
    B -->|Yes| D[Skip Status Check]
    C --> E[Load Entity from DB]
    D --> E
    E --> F[Update Status to PROCESSING]
    F --> G[Map Fields to State]
    G --> H[Validate Critical Fields]
    H --> I[Exit Prepare Node]

    style A fill:#ffe6e6
    style I fill:#ffe6e6
```

**èŒè´£**ï¼š
- éªŒè¯å®ä½“å­˜åœ¨æ€§
- ä»æ•°æ®åº“åŠ è½½å®ä½“æ•°æ®
- æ˜ å°„æ¨¡å‹å­—æ®µåˆ° State
- æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸º PROCESSINGï¼ˆé force æ¨¡å¼ï¼‰
- éªŒè¯å…³é”®å­—æ®µå®Œæ•´æ€§

**2. Business Nodes (ä¸šåŠ¡èŠ‚ç‚¹)**

```mermaid
graph LR
    A[Enter Business Node] --> B{Can Enter?}
    B -->|No| C[Skip Node]
    B -->|Yes| D[Before Processing]
    D --> E[Execute Business Logic]
    E --> F[Update State Results]
    F --> G[After Processing]
    G --> H{Has Error?}
    H -->|Yes| I[Add Node Error]
    H -->|No| J[Exit Business Node]
    I --> J

    style A fill:#e6ffe6
    style J fill:#e6ffe6
```

**èŒè´£**ï¼š
- æ£€æŸ¥å‡†å…¥æ¡ä»¶ï¼ˆä¾èµ–å­—æ®µæ˜¯å¦å­˜åœ¨ï¼‰
- æ‰§è¡Œæ ¸å¿ƒä¸šåŠ¡é€»è¾‘
- åªè¯»å†™ LangGraph Stateï¼Œä¸è®¿é—®æ•°æ®åº“
- å°†å¤„ç†ç»“æœå†™å…¥ State çš„ç»“æœå­—æ®µ
- é”™è¯¯é€šè¿‡ State çš„ node_errors è®°å½•

**3. Finalize Node (å°¾èŠ‚ç‚¹)**

```mermaid
graph LR
    A[Enter Finalize Node] --> B{Has Node Errors?}
    B -->|Yes| C[Update Status to FAILED]
    B -->|No| D[Sync Results to DB]
    D --> E{Force Mode?}
    C --> E
    E -->|No| F[Update Status to SUCCESS/FAILED]
    E -->|Yes| G[Skip Status Update]
    F --> H[Exit Finalize Node]
    G --> H

    style A fill:#ffe6e6
    style H fill:#ffe6e6
```

**èŒè´£**ï¼š
- æ£€æŸ¥ State ä¸­çš„ node_errors
- å¦‚æœæœ‰é”™è¯¯ï¼šåªæ›´æ–°çŠ¶æ€ä¸º FAILED
- å¦‚æœæ— é”™è¯¯ï¼š
  - åŸå­æ€§åœ°å°† State ç»“æœåŒæ­¥åˆ°æ•°æ®åº“
  - æ›´æ–°çŠ¶æ€ä¸º SUCCESS
- Force æ¨¡å¼ä¸‹è·³è¿‡çŠ¶æ€æ›´æ–°

### æ£€æŸ¥ç‚¹æ¶æ„

```mermaid
graph TB
    subgraph "Checkpoint Configuration"
        TC[Thread Config]
        TC --> TID[thread_id: workflow_entity_id]
        TC --> NS[checkpoint_ns: feature_name]
        TC --> CID[checkpoint_id: optional]
    end

    subgraph "Redis Storage Structure"
        RS[Redis Keys]
        RS --> K1["checkpoint:thread_id:version"]
        RS --> K2["metadata:thread_id:version"]
        RS --> K3["index:thread_id"]
    end

    subgraph "Checkpoint Content"
        CC[Checkpoint Data]
        CC --> CS[Complete State]
        CC --> CM[Metadata]
        CC --> CE[Execution History]
    end

    subgraph "TTL Management"
        TTL[TTL Configuration]
        TTL --> DT[default_ttl: 24 hours]
        TTL --> RT[refresh_on_read: true]
    end

    TC -.-> RS
    RS -.-> CC
    CC -.-> TTL
```

**Checkpoint ç‰¹æ€§**ï¼š
- **è‡ªåŠ¨ä¿å­˜**: æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåè‡ªåŠ¨ä¿å­˜ State
- **ç‰ˆæœ¬ç®¡ç†**: æ”¯æŒå¤šç‰ˆæœ¬ checkpointï¼Œå¯ä»¥å›æº¯åˆ°ä»»æ„èŠ‚ç‚¹
- **TTL æœºåˆ¶**: è‡ªåŠ¨è¿‡æœŸæ¸…ç†ï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´
- **åŸå­æ“ä½œ**: ä½¿ç”¨ Redis äº‹åŠ¡ç¡®ä¿ä¸€è‡´æ€§

## ç»„ä»¶ä¸æ¥å£

### ç»„ä»¶å±‚æ¬¡ç»“æ„

```
threadline/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ email_state.py              # Email State å®šä¹‰
â”‚   â”œâ”€â”€ checkpoint_manager.py       # Checkpoint ç®¡ç†å™¨
â”‚   â”œâ”€â”€ workflow.py                 # å·¥ä½œæµç¼–æ’
â”‚   â””â”€â”€ nodes/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ base_node.py            # åŸºç¡€èŠ‚ç‚¹ç±»
â”‚       â”œâ”€â”€ workflow_prepare.py     # å‡†å¤‡èŠ‚ç‚¹
â”‚       â”œâ”€â”€ workflow_finalize.py    # å®ŒæˆèŠ‚ç‚¹
â”‚       â”œâ”€â”€ ocr_node.py             # OCR å¤„ç†èŠ‚ç‚¹
â”‚       â”œâ”€â”€ llm_ocr_node.py         # LLM OCR å¤„ç†èŠ‚ç‚¹
â”‚       â”œâ”€â”€ llm_email_node.py       # LLM Email å¤„ç†èŠ‚ç‚¹
â”‚       â”œâ”€â”€ summary_node.py         # æ‘˜è¦ç”ŸæˆèŠ‚ç‚¹
â”‚       â””â”€â”€ issue_node.py           # Issue åˆ›å»ºèŠ‚ç‚¹
```

### æ ¸å¿ƒæ¥å£

#### 1. çŠ¶æ€å®šä¹‰æ¥å£

```python
# [feature]_state.py

from typing import TypedDict, List, Dict, Any
from datetime import datetime

class NodeError(TypedDict):
    """Node-specific error information."""
    error_message: str
    timestamp: str

class [Feature]State(TypedDict, total=False):
    """
    State structure for [feature] workflow.

    Three categories of fields:
    1. Core fields: Mapped from Django model
    2. Result fields: Generated by workflow processing
    3. Fixed fields: Common control fields
    """
    # Core fields (from Django model)
    id: str
    user_id: str
    [model_field_1]: type_hint
    [model_field_2]: type_hint
    # ... other model fields

    # Result fields (workflow outputs)
    [result_field_1]: type_hint | None
    [result_field_2]: type_hint | None
    # ... other result fields

    # Fixed fields (always present)
    error_message: str | None
    node_errors: Dict[str, List[NodeError]] | None
    force: bool | None

def create_[feature]_state(
    entity_id: str,
    user_id: str,
    force: bool = False
) -> [Feature]State:
    """
    Create initial state for workflow execution.

    Args:
        entity_id: Primary identifier
        user_id: User identifier
        force: Force processing flag

    Returns:
        Initialized state with default values
    """
    return {
        "id": entity_id,
        "user_id": user_id,
        # Initialize all fields with default values
        "error_message": None,
        "node_errors": {},
        "force": force,
    }

# State helper functions
def add_node_error(
    state: [Feature]State,
    node_name: str,
    error_message: str
) -> [Feature]State:
    """Add error to specific node."""

def has_node_errors(state: [Feature]State) -> bool:
    """Check if any node has errors."""

def get_node_errors_by_name(
    state: [Feature]State,
    node_name: str
) -> List[NodeError]:
    """Get errors for specific node."""
```

#### 2. èŠ‚ç‚¹æ¥å£

```python
# nodes/base_node.py

from abc import ABC, abstractmethod
from typing import TypeVar

StateType = TypeVar('StateType')

class BaseLangGraphNode(ABC):
    """
    Abstract base class for LangGraph nodes.

    Lifecycle:
        1. __call__: Entry point
        2. can_enter_node: Check entry conditions
        3. before_processing: Pre-processing hook
        4. execute_processing: Core business logic
        5. after_processing: Post-processing hook
        6. _handle_error: Error handling
    """

    def __init__(self, node_name: str):
        """Initialize node with name."""
        self.node_name = node_name
        self.logger = logging.getLogger(__name__)

    def __call__(self, state: StateType) -> StateType:
        """
        Main entry point for node execution.

        Orchestrates:
        - Entry condition checking
        - Lifecycle execution
        - Error handling
        """
        try:
            if not self.can_enter_node(state):
                self.logger.info(
                    f"Skipping {self.node_name} - entry conditions not met"
                )
                return state

            state = self.before_processing(state)
            state = self.execute_processing(state)
            state = self.after_processing(state)

            return state
        except Exception as error:
            return self._handle_error(error, state)

    def can_enter_node(self, state: StateType) -> bool:
        """
        Check if node can be entered.

        Default: Check for existing errors
        Override: Add dependency checks
        """
        return not has_node_errors(state)

    def before_processing(self, state: StateType) -> StateType:
        """Pre-processing hook. Override if needed."""
        return state

    @abstractmethod
    def execute_processing(self, state: StateType) -> StateType:
        """
        Core business logic.

        Must be implemented by subclasses.
        Should focus on business logic only.
        """
        pass

    def after_processing(self, state: StateType) -> StateType:
        """Post-processing hook. Override if needed."""
        return state

    def _handle_error(
        self, error: Exception, state: StateType
    ) -> StateType:
        """
        Handle errors during node execution.

        Adds error to state's node_errors.
        """
        self.logger.error(
            f"Error in {self.node_name}: {str(error)}"
        )
        return add_node_error(state, self.node_name, str(error))
```

#### 3. å·¥ä½œæµæ¥å£

```python
# workflow.py

from functools import lru_cache
from typing import Dict, Any

from langgraph.graph import StateGraph, START, END

from threadline.agents.email_state import EmailState, create_email_state
from threadline.agents.checkpoint_manager import create_checkpointer
from threadline.agents.nodes.workflow_prepare import WorkflowPrepareNode
from threadline.agents.nodes.workflow_finalize import WorkflowFinalizeNode
# Import business nodes
from threadline.agents.nodes.ocr_node import OCRNode
from threadline.agents.nodes.llm_ocr_node import LLMOCRNode
from threadline.agents.nodes.llm_email_node import LLMEmailNode
from threadline.agents.nodes.summary_node import SummaryNode
from threadline.agents.nodes.issue_node import IssueNode

@lru_cache(maxsize=1)
def create_email_graph():
    """
    Create and compile the email processing StateGraph.

    Node flow (with parallel execution):
        START â†’ Prepare â†’ â”¬â†’ OCR â†’ LLM OCR â”¬â†’ Summary â†’ Issue â†’ Finalize â†’ END
                          â””â†’ LLM Email â”€â”€â”€â”€â”€â”˜

    Parallel execution enables OCR processing and email content processing
    to run simultaneously, reducing total workflow time.

    Returns:
        Compiled StateGraph with Redis checkpoint
    """
    workflow = StateGraph(EmailState)

    # Add nodes
    workflow.add_node("workflow_prepare_node", WorkflowPrepareNode())
    workflow.add_node("ocr_node", OCRNode())
    workflow.add_node("llm_ocr_node", LLMOCRNode())
    workflow.add_node("llm_email_node", LLMEmailNode())
    workflow.add_node("summary_node", SummaryNode())
    workflow.add_node("issue_node", IssueNode())
    workflow.add_node("workflow_finalize_node", WorkflowFinalizeNode())

    # Define edges with parallel branches
    workflow.add_edge(START, "workflow_prepare_node")

    # Parallel execution: OCR path and Email path
    workflow.add_edge("workflow_prepare_node", "ocr_node")
    workflow.add_edge("workflow_prepare_node", "llm_email_node")

    # OCR path continues
    workflow.add_edge("ocr_node", "llm_ocr_node")

    # Both paths converge at summary_node
    workflow.add_edge("llm_ocr_node", "summary_node")
    workflow.add_edge("llm_email_node", "summary_node")

    # Sequential after summary
    workflow.add_edge("summary_node", "issue_node")
    workflow.add_edge("issue_node", "workflow_finalize_node")
    workflow.add_edge("workflow_finalize_node", END)

    # Compile with Redis checkpointer
    checkpointer = create_checkpointer()
    graph = workflow.compile(checkpointer=checkpointer)

    return graph

def execute_email_workflow(
    email_id: str,
    force: bool = False
) -> Dict[str, Any]:
    """
    Execute the complete email processing workflow.

    Args:
        email_id: ID of the email to process
        force: Force processing regardless of status

    Returns:
        Dict containing:
        - success: bool
        - has_errors: bool
        - error_nodes: List[str]
        - state: Final state
    """
    from threadline.models import EmailMessage

    # Validate entity exists
    email = EmailMessage.objects.get(id=email_id)

    # Create initial state
    initial_state = create_email_state(
        email_id,
        str(email.user_id),
        force
    )

    # Configure checkpoint
    config = {
        "configurable": {
            "thread_id": f"email_workflow_{email_id}",
            "checkpoint_ns": "email_processing"
        }
    }

    # Execute workflow
    graph = create_email_graph()
    final_state = graph.invoke(initial_state, config=config)

    # Check results
    has_errors = has_node_errors(final_state)
    error_nodes = (
        get_all_node_names_with_errors(final_state) if has_errors else []
    )

    return {
        "success": not has_errors,
        "has_errors": has_errors,
        "error_nodes": error_nodes,
        "state": final_state
    }
```

#### 4. æ£€æŸ¥ç‚¹ç®¡ç†å™¨æ¥å£

```python
# checkpoint_manager.py

from langgraph.checkpoint.redis import RedisSaver

def create_checkpointer() -> RedisSaver:
    """
    Create Redis checkpointer for LangGraph.

    Configuration:
    - Uses CELERY_BROKER_URL from Django settings
    - TTL: 24 hours
    - Refresh on read: enabled

    Returns:
        Configured RedisSaver instance
    """
    redis_url = settings.CELERY_BROKER_URL
    context_manager = RedisSaver.from_conn_string(
        redis_url,
        ttl={
            "default_ttl": 60 * 24,  # 24 hours
            "refresh_on_read": True
        }
    )
    checkpointer = context_manager.__enter__()
    checkpointer.setup()
    return checkpointer
```

### èŠ‚ç‚¹å®ç°æ¨¡å¼

#### æ¨¡å¼ 1ï¼šå‡†å¤‡èŠ‚ç‚¹å®ç°

```python
class WorkflowPrepareNode(BaseLangGraphNode):
    """First node - loads data from database to state."""

    def __init__(self):
        super().__init__("workflow_prepare_node")
        self.entity = None

    def before_processing(self, state: EmailState) -> EmailState:
        """Load email from database."""
        from threadline.models import EmailMessage

        email_id = state.get('id')
        self.entity = EmailMessage.objects.get(id=email_id)
        return state

    def execute_processing(self, state: EmailState) -> EmailState:
        """
        Map email fields to state and update status.

        Force mode: Skip status update
        Normal mode: Set status to PROCESSING
        """
        force = state.get('force', False)

        # Update database status (unless force mode)
        if not force:
            self.entity.set_status(EmailStatus.PROCESSING.value)

        # Map all model fields to state
        updated_state = {
            **state,
            'id': str(self.entity.id),
            'user_id': str(self.entity.user_id),
            '[field_1]': self.entity.[field_1],
            '[field_2]': self.entity.[field_2],
            # ... map all required fields
        }

        return updated_state

    def after_processing(self, state: StateType) -> StateType:
        """Validate critical fields."""
        # Check required fields for downstream processing
        if not state.get('[critical_field]'):
            raise ValueError("Missing critical field")
        return state
```

#### æ¨¡å¼ 2ï¼šä¸šåŠ¡èŠ‚ç‚¹å®ç°

```python
class LLMEmailNode(BaseLangGraphNode):
    """
    LLM processing for email content.

    Example business node - pure state operations.
    """

    def __init__(self):
        super().__init__("llm_email_node")

    def can_enter_node(self, state: EmailState) -> bool:
        """
        Check dependencies and entry conditions.

        Requires email content to be present.
        """
        if not super().can_enter_node(state):
            return False

        # Check if required email content exists
        email_content = state.get('content')
        if not email_content:
            self.logger.warning(
                "Missing email content, skipping LLM processing"
            )
            return False

        return True

    def execute_processing(self, state: EmailState) -> EmailState:
        """
        Execute business logic - only operate on state.

        Do NOT access database directly.
        Read from state, write results back to state.
        """
        from threadline.utils.llm_utils import process_email_with_llm

        # Read input from state
        email_content = state.get('content')
        subject = state.get('subject')

        # Execute business logic
        llm_result = process_email_with_llm(
            subject=subject,
            content=email_content
        )

        # Write result back to state
        updated_state = {
            **state,
            'llm_processed_content': llm_result.get('processed_content'),
            'extracted_entities': llm_result.get('entities', [])
        }

        return updated_state
```

#### æ¨¡å¼ 3ï¼šå®ŒæˆèŠ‚ç‚¹å®ç°

```python
class WorkflowFinalizeNode(BaseLangGraphNode):
    """Last node - syncs state results to database."""

    def __init__(self):
        super().__init__("workflow_finalize_node")
        self.entity = None

    def can_enter_node(self, state: StateType) -> bool:
        """Finalize always runs to ensure cleanup."""
        return True

    def before_processing(self, state: EmailState) -> EmailState:
        """Load email for database operations."""
        from threadline.models import EmailMessage

        email_id = state.get('id')
        self.entity = EmailMessage.objects.get(id=email_id)
        return state

    def execute_processing(self, state: EmailState) -> EmailState:
        """
        Sync results and update final status.

        If errors exist: Set FAILED status
        If no errors: Sync data to DB and set COMPLETED status
        """
        has_errors = has_node_errors(state)
        force = state.get('force', False)

        if has_errors:
            # Only update status to FAILED
            if not force:
                error_nodes = get_all_node_names_with_errors(state)
                self.entity.set_status(
                    EmailStatus.FAILED.value,
                    error_message=f"Failed in nodes: {error_nodes}"
                )
        else:
            # Sync data and set COMPLETED
            self._sync_data_to_database(state)
            if not force:
                self.entity.set_status(EmailStatus.COMPLETED.value)

        return state

    def _sync_data_to_database(self, state: EmailState) -> None:
        """
        Atomically sync all results to database.

        Uses transaction and select_for_update for consistency.
        """
        from threadline.models import EmailMessage

        with transaction.atomic():
            email = EmailMessage.objects.select_for_update().get(
                id=self.entity.id
            )

            # Sync result fields
            email.llm_processed_content = state.get('llm_processed_content')
            email.summary = state.get('summary')
            email.issue_url = state.get('issue_url')

            email.save()
```

## Data Models

### çŠ¶æ€æ¨¡å‹ç»“æ„

```mermaid
classDiagram
    class NodeError {
        +string error_message
        +string timestamp
    }

    class FeatureState {
        <<TypedDict>>
        +string id
        +string user_id
        +ModelFields... core_fields
        +ResultFields... result_fields
        +string error_message
        +Dict node_errors
        +bool force
    }

    class StateHelpers {
        +create_state()
        +add_node_error()
        +has_node_errors()
        +get_node_errors_by_name()
        +clear_node_errors()
    }

    FeatureState --> NodeError : contains
    StateHelpers --> FeatureState : operates on
```

### Django æ¨¡å‹ç®€åŒ–

**é‡æ„å‰ï¼ˆå¤æ‚çŠ¶æ€æœºï¼‰**ï¼š
```python
class ProcessingStatus(models.TextChoices):
    CREATED = "CREATED", "Created"
    FETCHED = "FETCHED", "Fetched"
    OCR_PROCESSING = "OCR_PROCESSING", "OCR Processing"
    OCR_SUCCESS = "OCR_SUCCESS", "OCR Success"
    OCR_FAILED = "OCR_FAILED", "OCR Failed"
    LLM_OCR_PROCESSING = "LLM_OCR_PROCESSING", "LLM OCR Processing"
    LLM_OCR_SUCCESS = "LLM_OCR_SUCCESS", "LLM OCR Success"
    LLM_OCR_FAILED = "LLM_OCR_FAILED", "LLM OCR Failed"
    # ... 13+ states
```

**é‡æ„åï¼ˆç®€åŒ–çŠ¶æ€æœºï¼‰**ï¼š
```python
class ProcessingStatus(models.TextChoices):
    CREATED = "CREATED", "Created"
    FETCHED = "FETCHED", "Fetched"
    PROCESSING = "PROCESSING", "Processing"
    SUCCESS = "SUCCESS", "Success"
    FAILED = "FAILED", "Failed"
```

**State Transition Rules**:
```mermaid
stateDiagram-v2
    [*] --> CREATED: Initial
    CREATED --> FETCHED: Data Fetched
    FETCHED --> PROCESSING: Workflow Started
    PROCESSING --> SUCCESS: All Nodes Success
    PROCESSING --> FAILED: Any Node Failed
    FAILED --> PROCESSING: Retry
    SUCCESS --> [*]: Complete
```

### æ£€æŸ¥ç‚¹æ•°æ®ç»“æ„

```python
# Redis checkpoint structure
checkpoint = {
    "config": {
        "configurable": {
            "thread_id": "workflow_entity_123",
            "checkpoint_ns": "email_processing"
        }
    },
    "state": {
        # Complete FeatureState
        "id": "entity_123",
        "user_id": "user_456",
        # ... all state fields
    },
    "metadata": {
        "timestamp": "2024-01-01T12:00:00Z",
        "node_name": "ocr_node",
        "version": 3
    },
    "parent_config": {
        # Previous checkpoint config
    }
}
```

## é”™è¯¯å¤„ç†

### é”™è¯¯å¤„ç†ç­–ç•¥

```mermaid
graph TD
    A[Node Execution] --> B{Exception Occurs?}
    B -->|Yes| C[BaseLangGraphNode._handle_error]
    B -->|No| D[Continue to Next Node]

    C --> E[Log Error]
    E --> F[add_node_error to State]
    F --> G[Return State with Error]

    G --> H[Continue to Next Node]
    H --> I[Eventually Reach Finalize Node]

    I --> J{has_node_errors?}
    J -->|Yes| K[Set Status to FAILED]
    J -->|No| L[Sync Data & Set SUCCESS]

    K --> M[Skip Data Sync]
    M --> N[End Workflow]
    L --> N

    style C fill:#ffcccc
    style F fill:#ffcccc
    style K fill:#ffcccc
```

### é”™è¯¯ç±»å‹ä¸å¤„ç†

#### 1. èŠ‚ç‚¹æ‰§è¡Œé”™è¯¯

**å¤„ç†æ–¹å¼**ï¼šè®°å½•åˆ°çŠ¶æ€ä¸­ï¼Œç»§ç»­å·¥ä½œæµ
```python
try:
    result = self._execute_business_logic(state)
except BusinessLogicError as error:
    # Record error but don't stop workflow
    return add_node_error(state, self.node_name, str(error))
```

#### 2. å…³é”®åŸºç¡€è®¾æ–½é”™è¯¯

**å¤„ç†æ–¹å¼**ï¼šæŠ›å‡ºå¼‚å¸¸ï¼Œåœæ­¢å·¥ä½œæµ
```python
from threadline.models import EmailMessage

try:
    email = EmailMessage.objects.get(id=email_id)
except EmailMessage.DoesNotExist:
    # Critical error - stop immediately
    raise ValueError(f"Email {email_id} not found")
```

#### 3. æ•°æ®åº“æ“ä½œé”™è¯¯

**å¤„ç†æ–¹å¼**ï¼šåŸå­äº‹åŠ¡ä¸å›æ»š
```python
from threadline.models import EmailMessage
from django.db import transaction

try:
    with transaction.atomic():
        email = EmailMessage.objects.select_for_update().get(id=email_id)
        email.summary = new_summary
        email.save()
except DatabaseError as error:
    # Transaction automatically rolled back
    return add_node_error(state, self.node_name, str(error))
```

#### 4. æ£€æŸ¥ç‚¹é”™è¯¯

**å¤„ç†æ–¹å¼**ï¼šè®°å½•è­¦å‘Šï¼Œç»§ç»­æ‰§è¡Œ
```python
try:
    checkpointer.save(config, state)
except CheckpointError as error:
    # Log but don't stop workflow
    logger.warning(f"Checkpoint save failed: {error}")
    # Workflow continues without checkpoint
```

### é”™è¯¯æ¢å¤æœºåˆ¶

#### 1. ä»æ£€æŸ¥ç‚¹è‡ªåŠ¨é‡è¯•

```python
# Resume from last successful checkpoint
config = {
    "configurable": {
        "thread_id": f"workflow_{entity_id}",
        "checkpoint_ns": "feature_processing"
    }
}

# LangGraph automatically resumes from last checkpoint
result = graph.invoke(initial_state, config=config)
```

#### 2. å¼ºåˆ¶æ¨¡å¼æ¢å¤

```python
# Force reprocessing to fix data issues
result = execute_[feature]_workflow(
    entity_id,
    force=True  # Skip status checks, reprocess everything
)
```

#### 3. é€‰æ‹©æ€§èŠ‚ç‚¹é‡è¯•

```python
# Get state from checkpoint
checkpoint_manager = get_checkpoint_manager()
state = checkpoint_manager.load_checkpoint(config)

# Clear specific node errors
state = clear_node_errors_by_name(state, "problematic_node")

# Resume workflow
result = graph.invoke(state, config=config)
```

### é”™è¯¯æ—¥å¿—ä¸ç›‘æ§

```python
# Node error structure
{
    "node_name": "ocr_node",
    "errors": [
        {
            "error_message": "OCR processing failed: Invalid image format",
            "timestamp": "2024-01-01T12:00:00Z"
        }
    ]
}

# Logging strategy
logger.error(
    f"[{node_name}] Processing failed for entity {entity_id}: {error}"
)
logger.info(
    f"[workflow_finalize_node] Workflow failed with errors in "
    f"nodes: {error_nodes}"
)
```

## æµ‹è¯•ç­–ç•¥

### æµ‹è¯•é‡‘å­—å¡”

```mermaid
graph TD
    E2E[End-to-End Tests<br/>Integration with real services]
    INT[Integration Tests<br/>Full workflow execution]
    UNIT[Unit Tests<br/>Individual node logic]

    UNIT --> INT
    INT --> E2E

    style UNIT fill:#99ff99
    style INT fill:#ffff99
    style E2E fill:#ff9999
```

### å•å…ƒæµ‹è¯•

**èŒƒå›´**ï¼šå•ä¸ªèŠ‚ç‚¹ä¸šåŠ¡é€»è¾‘

```python
# Test node can_enter_node logic
def test_llm_email_node_can_enter_with_content():
    state = {
        "id": "test_123",
        "content": "Email content here",
        "subject": "Test Subject"
    }
    node = LLMEmailNode()
    assert node.can_enter_node(state) == True

def test_llm_email_node_cannot_enter_without_content():
    state = {
        "id": "test_123",
        "subject": "Test Subject"
        # missing content
    }
    node = LLMEmailNode()
    assert node.can_enter_node(state) == False

# Test node business logic
def test_llm_email_node_processing():
    state = {
        "id": "test_123",
        "content": "Email content to process",
        "subject": "Test Email"
    }
    node = LLMEmailNode()
    with patch('threadline.utils.llm_utils.process_email_with_llm') as mock_llm:
        mock_llm.return_value = {
            'processed_content': 'Processed content',
            'entities': ['entity1', 'entity2']
        }
        result = node.execute_processing(state)
    assert result["llm_processed_content"] == "Processed content"
    assert len(result["extracted_entities"]) == 2

# Test error handling
def test_ocr_node_handles_errors():
    state = {
        "id": "test_123",
        "attachments": [{"is_image": True, "file_path": "/path/to/image.jpg"}]
    }
    node = OCRNode()
    # Simulate error
    with patch('threadline.utils.ocr_utils.process_image_ocr', side_effect=Exception("OCR failed")):
        result = node(state)
    assert has_node_errors(result)
    assert "OCR failed" in str(get_node_errors_by_name(result, node.node_name))
```

### é›†æˆæµ‹è¯•

**èŒƒå›´**ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®åº“çš„å®Œæ•´å·¥ä½œæµæ‰§è¡Œ

```python
@pytest.fixture
def mock_email():
    """Create mock email for testing."""
    email = MagicMock()
    email.id = "test_123"
    email.user_id = "user_456"
    email.subject = "Test Email"
    email.content = "Test email content"
    return email

def test_email_workflow_success_path(mock_email):
    """Test complete email workflow with all nodes succeeding."""
    with patch('threadline.models.EmailMessage.objects.get', return_value=mock_email):
        result = execute_email_workflow("test_123", force=False)

    assert result["success"] == True
    assert result["has_errors"] == False
    assert len(result["error_nodes"]) == 0

def test_email_workflow_with_node_failure(mock_email):
    """Test workflow continues after node failure."""
    with patch('threadline.models.EmailMessage.objects.get', return_value=mock_email):
        with patch.object(OCRNode, 'execute_processing',
                         side_effect=Exception("OCR processing failed")):
            result = execute_email_workflow("test_123", force=False)

    assert result["success"] == False
    assert result["has_errors"] == True
    assert "ocr_node" in result["error_nodes"]

def test_email_workflow_force_mode(mock_email):
    """Test force mode skips status checks."""
    mock_email.status = EmailStatus.COMPLETED.value
    with patch('threadline.models.EmailMessage.objects.get', return_value=mock_email):
        result = execute_email_workflow("test_123", force=True)

    # Should execute even if already COMPLETED
    assert result["success"] == True
```

### æ£€æŸ¥ç‚¹æµ‹è¯•

**èŒƒå›´**ï¼šæ£€æŸ¥ç‚¹ä¿å­˜ä¸æ¢å¤

```python
def test_checkpoint_save_and_load():
    """Test checkpoint persistence and recovery."""
    entity_id = "test_123"
    config = {
        "configurable": {
            "thread_id": f"workflow_{entity_id}",
            "checkpoint_ns": "test_processing"
        }
    }

    # Execute workflow
    result = execute_[feature]_workflow(entity_id, force=False)

    # Load checkpoint
    manager = get_checkpoint_manager()
    checkpoint = manager.load_checkpoint(config)

    assert checkpoint is not None
    assert checkpoint["id"] == entity_id

def test_workflow_resume_from_checkpoint():
    """Test resuming workflow from checkpoint."""
    entity_id = "test_123"
    config = {
        "configurable": {
            "thread_id": f"workflow_{entity_id}"
        }
    }

    # Start workflow (will save checkpoints)
    graph = create_[feature]_graph()
    initial_state = create_[feature]_state(entity_id, "user_456")

    # Simulate interruption after first node
    # (In real scenario, would be interrupted by error or timeout)

    # Resume from checkpoint
    result = graph.invoke(initial_state, config=config)

    # Verify workflow completed
    assert not has_node_errors(result)
```

### ç«¯åˆ°ç«¯æµ‹è¯•

**èŒƒå›´**ï¼šä½¿ç”¨çœŸå®æ•°æ®åº“å’Œ Redis çš„å®Œæ•´ç³»ç»Ÿ

```python
@pytest.mark.django_db
def test_e2e_email_workflow_execution():
    """Test complete email workflow with real database."""
    from threadline.models import EmailMessage

    # Create test email
    email = EmailMessage.objects.create(
        user_id="user_123",
        subject="Test Email",
        content="Test email content",
        sender="test@example.com",
        status=EmailStatus.FETCHED.value
    )

    # Execute workflow
    result = execute_email_workflow(str(email.id), force=False)

    # Verify results
    assert result["success"] == True

    # Verify database state
    email.refresh_from_db()
    assert email.status == EmailStatus.COMPLETED.value
    assert email.summary is not None
    assert email.llm_processed_content is not None

@pytest.mark.django_db
def test_e2e_email_workflow_recovery_after_failure():
    """Test email workflow recovery after failure."""
    from threadline.models import EmailMessage

    email = EmailMessage.objects.create(
        user_id="user_123",
        subject="Test Email",
        content="Test content",
        sender="test@example.com",
        status=EmailStatus.FAILED.value
    )

    # Retry with force mode
    result = execute_email_workflow(str(email.id), force=True)

    # Verify recovery
    email.refresh_from_db()
    assert email.status == EmailStatus.COMPLETED.value
```

### æ€§èƒ½æµ‹è¯•

**èŒƒå›´**ï¼šå·¥ä½œæµæ‰§è¡Œæ—¶é—´å’Œèµ„æºä½¿ç”¨

```python
def test_workflow_performance():
    """Test workflow completes within acceptable time."""
    import time

    entity_id = "test_123"
    start_time = time.time()

    result = execute_[feature]_workflow(entity_id, force=False)

    end_time = time.time()
    execution_time = end_time - start_time

    # Assert workflow completes within 30 seconds
    assert execution_time < 30.0
    assert result["success"] == True

def test_checkpoint_overhead():
    """Test checkpoint save/load overhead."""
    import time

    state = create_[feature]_state("test_123", "user_456")
    config = {"configurable": {"thread_id": "perf_test"}}

    # Measure checkpoint save time
    manager = get_checkpoint_manager()
    start_time = time.time()
    manager.save_checkpoint(config, state)
    save_time = time.time() - start_time

    # Measure checkpoint load time
    start_time = time.time()
    loaded = manager.load_checkpoint(config)
    load_time = time.time() - start_time

    # Assert checkpoint operations are fast (<100ms)
    assert save_time < 0.1
    assert load_time < 0.1
```

### æµ‹è¯•æœ€ä½³å®è·µ

1. **Use fixtures for common setup**
   - Mock entities
   - Test states
   - Configuration objects

2. **Test both success and failure paths**
   - Normal execution
   - Error conditions
   - Edge cases

3. **Isolate external dependencies**
   - Mock database calls in unit tests
   - Mock external APIs
   - Use in-memory Redis for testing

4. **Verify state immutability**
   - Ensure nodes use `{**state, ...}` pattern
   - Verify original state is not modified

5. **Test force mode behavior**
   - Verify status checks are skipped
   - Verify status updates are skipped
   - Verify reprocessing works

## å®æ–½é˜¶æ®µ

### é˜¶æ®µ 1ï¼šåŸºç¡€è®¾ç½®ï¼ˆç¬¬ 1 å‘¨ï¼‰

**ç›®æ ‡**ï¼šå»ºç«‹åŸºæœ¬çš„ LangGraph åŸºç¡€è®¾æ–½

- [ ] Create `agents/` directory structure
- [ ] Implement `checkpoint_manager.py` (copy from reference)
- [ ] Implement `base_node.py` (copy from reference)
- [ ] Setup Redis checkpointer configuration
- [ ] Create unit test framework

### é˜¶æ®µ 2ï¼šçŠ¶æ€å®šä¹‰ï¼ˆç¬¬ 1 å‘¨ï¼‰

**ç›®æ ‡**ï¼šå®šä¹‰ç›®æ ‡å·¥ä½œæµçš„çŠ¶æ€ç»“æ„

- [ ] Analyze Django model structure
- [ ] Create `email_state.py` with TypedDict
- [ ] Map EmailMessage model fields to EmailState fields
- [ ] Define result fields (llm_processed_content, summary, issue_url, etc.)
- [ ] Implement State helper functions
- [ ] Write unit tests for State operations

### é˜¶æ®µ 3ï¼šèŠ‚ç‚¹å®ç°ï¼ˆç¬¬ 2 å‘¨ï¼‰

**ç›®æ ‡**ï¼šå®ç°å·¥ä½œæµèŠ‚ç‚¹

- [ ] Implement `workflow_prepare.py`
  - Database loading logic
  - Field mapping
  - Status update
- [ ] Implement `workflow_finalize.py`
  - Error checking
  - Data synchronization
  - Final status update
- [ ] Implement business nodes
  - OCRNode: Process image attachments with OCR
  - LLMOCRNode: Process OCR results with LLM
  - LLMEmailNode: Process email content with LLM
  - SummaryNode: Generate email summary
  - IssueNode: Create issues from email
- [ ] Write unit tests for each node

### é˜¶æ®µ 4ï¼šå·¥ä½œæµç¼–æ’ï¼ˆç¬¬ 2-3 å‘¨ï¼‰

**ç›®æ ‡**ï¼šåˆ›å»ºçŠ¶æ€å›¾å’Œå·¥ä½œæµæ‰§è¡Œ

- [ ] Implement `workflow.py`
  - `create_[feature]_graph()`
  - `execute_[feature]_workflow()`
- [ ] Configure node connections
- [ ] Setup checkpoint configuration
- [ ] Write integration tests
- [ ] Test checkpoint save/load

### é˜¶æ®µ 5ï¼šè¿ç§»ä¸é›†æˆï¼ˆç¬¬ 3 å‘¨ï¼‰

**ç›®æ ‡**ï¼šä¸ç°æœ‰ç³»ç»Ÿé›†æˆ

- [ ] Create Celery task compatibility wrapper
  - Maintain existing task signature
  - Delegate to LangGraph workflow
  - Preserve return value format
- [ ] **Verify** existing entry points (no changes needed):
  - API endpoints continue to work
  - Admin actions continue to work
  - Schedulers continue to work
- [ ] Parallel run testing (old + new implementations)
- [ ] Update internal documentation

### é˜¶æ®µ 6ï¼šæµ‹è¯•ä¸éªŒè¯ï¼ˆç¬¬ 4 å‘¨ï¼‰

**ç›®æ ‡**ï¼šå…¨é¢æµ‹è¯•

- [ ] Run all unit tests
- [ ] Run all integration tests
- [ ] End-to-end testing
- [ ] Performance testing
- [ ] Force mode testing
- [ ] Checkpoint recovery testing

### é˜¶æ®µ 7ï¼šç”Ÿäº§ç¯å¢ƒéƒ¨ç½²ï¼ˆç¬¬ 4 å‘¨ï¼‰

**ç›®æ ‡**ï¼šéƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ

- [ ] Documentation update
- [ ] Monitoring setup
- [ ] Gradual rollout (feature flag)
- [ ] Monitor error rates
- [ ] Performance monitoring
- [ ] Deprecate old Celery tasks

## è¿ç§»ç­–ç•¥

### å…¼å®¹æ€§å±‚

ä¿æŒä¸ç°æœ‰è°ƒç”¨æ–¹çš„å…¼å®¹æ€§ï¼ˆAPIã€Adminã€Scheduler ä¸éœ€è¦ä¿®æ”¹ï¼‰ï¼š

```python
# Celery task interface - maintains compatibility
@shared_task
def process_[feature]_task(entity_id: str, force: bool = False):
    """
    Celery task wrapper for [feature] processing.

    This task maintains the existing interface for backward compatibility.
    Internally, it delegates to the new LangGraph workflow implementation.

    Args:
        entity_id: ID of the entity to process
        force: Force processing regardless of current status

    Returns:
        str: entity_id (for Celery chain compatibility)
    """
    # Delegate to LangGraph workflow
    result = execute_[feature]_workflow(entity_id, force)

    # Return entity_id for compatibility with existing Celery chains
    return entity_id

# Alternative: You can also add a new direct interface
@shared_task
def process_[feature]_workflow(entity_id: str, force: bool = False):
    """
    New task interface that returns detailed workflow results.

    This provides more information than the legacy interface.
    """
    return execute_[feature]_workflow(entity_id, force)
```

**é‡è¦**ï¼š
- ç°æœ‰çš„ **API ç«¯ç‚¹**ã€**ç®¡ç†åå°æ“ä½œ**ã€**å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨**è°ƒç”¨ `process_[feature]_task`
- è¿™äº›è°ƒç”¨æ–¹**å®Œå…¨ä¸éœ€è¦ä¿®æ”¹**
- åªæœ‰ Celery ä»»åŠ¡å†…éƒ¨å®ç°æ”¹å˜ï¼ˆä» Celery é“¾æ”¹ä¸º LangGraphï¼‰

### å¹¶è¡Œæ‰§è¡Œæµ‹è¯•

```python
def compare_celery_vs_langgraph(entity_id: str):
    """
    Test function to compare Celery and LangGraph results.

    Execute both workflows and compare:
    - Execution time
    - Results accuracy
    - Error handling
    """
    import time

    # Execute Celery workflow
    celery_start = time.time()
    celery_result = process_[feature]_chain(entity_id, force=True)
    celery_time = time.time() - celery_start

    # Execute LangGraph workflow
    langgraph_start = time.time()
    langgraph_result = execute_[feature]_workflow(entity_id, force=True)
    langgraph_time = time.time() - langgraph_start

    # Compare results
    print(f"Celery time: {celery_time:.2f}s")
    print(f"LangGraph time: {langgraph_time:.2f}s")
    print(f"Results match: {compare_results(celery_result, langgraph_result)}")
```

### ç‰¹æ€§æ ‡å¿—æ§åˆ¶

```python
from django.conf import settings

def execute_workflow(entity_id: str, force: bool = False):
    """
    Smart router: Use LangGraph or Celery based on feature flag.
    """
    use_langgraph = getattr(settings, 'USE_LANGGRAPH_WORKFLOW', False)

    if use_langgraph:
        return execute_[feature]_workflow(entity_id, force)
    else:
        return process_[feature]_chain(entity_id, force)
```

## æ€§èƒ½è€ƒè™‘

### é¢„æœŸæ€§èƒ½ç‰¹å¾

1. **Execution Time**
   - Similar to Celery chain (minor overhead from checkpointing)
   - Checkpoint save: <50ms per node
   - Total overhead: <500ms for typical workflow

2. **Memory Usage**
   - State stored in memory during execution
   - Checkpoint stored in Redis
   - Memory efficient due to TypedDict

3. **Redis Storage**
   - Checkpoint size: Typically 1-10KB per state
   - TTL: 24 hours (auto-cleanup)
   - Storage impact: Minimal

### ä¼˜åŒ–ç­–ç•¥

1. **Minimize State Size**
   - Only include necessary fields
   - Use references instead of embedded data
   - Avoid storing large binary data

2. **Optimize Database Operations**
   - Use `select_for_update` for atomicity
   - Batch operations where possible
   - Use `select_related` for related objects

3. **Checkpoint Configuration**
   - Adjust TTL based on workflow characteristics
   - Consider checkpoint frequency trade-offs
   - Monitor Redis memory usage

## ç›‘æ§ä¸å¯è§‚å¯Ÿæ€§

### æ—¥å¿—ç­–ç•¥

```python
# Standard log format
logger.info(f"[{node_name}] Processing entity {entity_id}")
logger.error(f"[{node_name}] Error for {entity_id}: {error}")
logger.debug(f"[{node_name}] State: {state}")

# Workflow lifecycle logging
logger.info(f"[workflow] Started: {entity_id}, force: {force}")
logger.info(f"[workflow] Completed: {entity_id}, success: {success}")
```

### ç›‘æ§æŒ‡æ ‡

1. **Workflow Metrics**
   - Execution count
   - Success rate
   - Failure rate
   - Average execution time
   - Per-node execution time

2. **Checkpoint Metrics**
   - Checkpoint save rate
   - Checkpoint load rate
   - Checkpoint size distribution
   - Redis memory usage

3. **Error Metrics**
   - Errors by node
   - Error types distribution
   - Recovery success rate

### ä»ªè¡¨æ¿å»ºè®®

```
Workflow Overview Dashboard:
- Total executions (24h)
- Success rate (24h)
- Average execution time (24h)
- Active workflows (current)

Per-Node Dashboard:
- Execution count per node
- Error rate per node
- Average execution time per node

Checkpoint Dashboard:
- Checkpoint operations/sec
- Average checkpoint size
- Redis memory usage
- TTL expiration rate
```

## Email Processing é‡æ„å®ä¾‹

åŸºäºç°æœ‰çš„ `threadline/tasks/chain_orchestrator.py` Email Processing å·¥ä½œæµï¼Œä»¥ä¸‹æ˜¯å…·ä½“çš„é‡æ„å®æ–½æ–¹æ¡ˆã€‚

### å½“å‰ Celery é“¾ç»“æ„

```python
# threadline/tasks/chain_orchestrator.py
@shared_task
def process_email_chain(email_id: str, force: bool = False) -> str:
    """
    Current implementation with 5 sequential tasks:
    1. ocr_images_for_email - OCR processing for image attachments
    2. llm_ocr_task - LLM processing for attachments OCR
    3. llm_email_task - LLM processing for email body
    4. summarize_email_task - Email summarization
    5. create_issue_task - JIRA issue creation

    Status Flow:
    FETCHED â†’ OCR_PROCESSING â†’ OCR_SUCCESS
            â†’ LLM_OCR_PROCESSING â†’ LLM_OCR_SUCCESS
            â†’ LLM_EMAIL_PROCESSING â†’ LLM_EMAIL_SUCCESS
            â†’ LLM_SUMMARY_PROCESSING â†’ LLM_SUMMARY_SUCCESS
            â†’ ISSUE_PROCESSING â†’ ISSUE_SUCCESS â†’ COMPLETED
    """
```

### ç›®æ ‡ LangGraph ç»“æ„

```mermaid
graph TB
    START --> PrepNode[Prepare Node]

    PrepNode --> OCRNode[OCR Node]
    PrepNode --> LLM_EmailNode[LLM Email Node]

    OCRNode --> LLM_OCRNode[LLM Attachment Node]

    LLM_OCRNode --> SummaryNode[Summary Node]
    LLM_EmailNode --> SummaryNode[Summary Node]

    SummaryNode --> IssueNode[Issue Node]
    IssueNode --> FinalNode[Finalize Node]
    FinalNode --> END

    style PrepNode fill:#ff9999
    style FinalNode fill:#ff9999
    style OCRNode fill:#99ff99
    style LLM_OCRNode fill:#99ff99
    style LLM_EmailNode fill:#99ff99
    style SummaryNode fill:#99ff99
    style IssueNode fill:#99ff99

    classDef concurrent fill:#99ff99,stroke:#333,stroke-width:3px
    class OCRNode,LLM_EmailNode concurrent
```

#### å¹¶å‘æ‰§è¡Œè®¾è®¡è¯´æ˜

**å…³é”®æ”¹è¿›ï¼šä»ä¸²è¡Œåˆ°å¹¶å‘**

åŸ Celery é“¾æ˜¯**å®Œå…¨ä¸²è¡Œ**æ‰§è¡Œï¼š
```
OCR â†’ LLM_OCR â†’ LLM_Email â†’ Summary â†’ Issue
```

æ–° LangGraph è®¾è®¡è¯†åˆ«å‡º**ä¸¤æ¡ç‹¬ç«‹å¤„ç†è·¯å¾„**ï¼š
1. **é™„ä»¶å¤„ç†è·¯å¾„**ï¼š`OCR Node â†’ LLM Attachment Node`
2. **é‚®ä»¶å†…å®¹è·¯å¾„**ï¼š`LLM Email Node`

è¿™ä¸¤æ¡è·¯å¾„å¯ä»¥**å¹¶å‘æ‰§è¡Œ**ï¼Œå› ä¸ºï¼š
- OCR å¤„ç†çš„æ˜¯å›¾ç‰‡é™„ä»¶
- LLM Email å¤„ç†çš„æ˜¯é‚®ä»¶æ­£æ–‡å†…å®¹
- ä¸¤è€…äº’ä¸ä¾èµ–ï¼Œæ²¡æœ‰æ•°æ®ç«äº‰

**å¹¶å‘æ±‡èšç‚¹**ï¼š
- Summary Node ç­‰å¾…**ä¸¤æ¡è·¯å¾„éƒ½å®Œæˆ**åå†æ‰§è¡Œ
- LangGraph è‡ªåŠ¨å¤„ç†å¤šè¾“å…¥è¾¹çš„åŒæ­¥

**æ€§èƒ½æå‡é¢„ä¼°**ï¼š
- å‡è®¾ OCR è·¯å¾„è€—æ—¶ 10sï¼ŒEmail è·¯å¾„è€—æ—¶ 8s
- ä¸²è¡Œæ‰§è¡Œï¼š10s + 8s = 18s
- å¹¶å‘æ‰§è¡Œï¼šmax(10s, 8s) = 10s
- **æå‡çº¦ 44%**

### Email Processing çŠ¶æ€å®šä¹‰

```python
# threadline/agents/email_state.py

from typing import TypedDict, List, Dict, Any
from datetime import datetime

class NodeError(TypedDict):
    """Node-specific error information."""
    error_message: str
    timestamp: str

class EmailState(TypedDict, total=False):
    """
    State structure for email processing workflow.

    Replaces 13-state machine with simplified state + LangGraph State.
    """
    # Core EmailMessage fields
    id: str
    user_id: str
    task_id: str
    message_id: str
    subject: str
    sender: str
    recipients: str
    received_at: str
    raw_content: str
    html_content: str
    text_content: str

    # Attachment information (list of attachment dicts)
    attachments: List[Dict[str, Any]] | None

    # Processing results (populated by workflow nodes)
    summary_title: str | None
    summary_content: str | None
    summary_priority: str | None
    llm_content: str | None

    # Issue creation result
    issue_key: str | None
    issue_url: str | None

    # Fixed workflow fields
    error_message: str | None
    node_errors: Dict[str, List[NodeError]] | None
    force: bool | None

def create_email_state(
    email_id: str,
    user_id: str,
    force: bool = False
) -> EmailState:
    """Create initial EmailState for workflow execution."""
    return {
        "id": email_id,
        "user_id": user_id,
        "attachments": [],
        "summary_title": None,
        "summary_content": None,
        "summary_priority": None,
        "llm_content": None,
        "issue_key": None,
        "issue_url": None,
        "error_message": None,
        "node_errors": {},
        "force": force,
    }
```

### å·¥ä½œæµå®ç°

```python
# threadline/agents/workflow.py

from functools import lru_cache
from langgraph.graph import StateGraph, START, END

from threadline.agents.email_state import EmailState
from threadline.agents.checkpoint_manager import create_checkpointer
from threadline.agents.nodes.workflow_prepare import WorkflowPrepareNode
from threadline.agents.nodes.ocr_node import OCRNode
from threadline.agents.nodes.llm_attachment_node import LLMAttachmentNode
from threadline.agents.nodes.llm_email_node import LLMEmailNode
from threadline.agents.nodes.summary_node import SummaryNode
from threadline.agents.nodes.issue_node import IssueNode
from threadline.agents.nodes.workflow_finalize import WorkflowFinalizeNode

@lru_cache(maxsize=1)
def create_email_processing_graph():
    """
    Create and compile the email processing StateGraph.

    Replaces: threadline/tasks/chain_orchestrator.py

    Node flow (with parallel execution):
        START â†’ Prepare â†’ â”¬â†’ OCR â†’ LLM_Attachment â”¬â†’ Summary â†’ Issue â†’ Finalize â†’ END
                          â””â†’ LLM_Email â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Key features:
    - OCR path and LLM_Email path execute in parallel after Prepare
    - Summary waits for both paths to complete
    - Reduces total execution time by ~30-40%
    """
    workflow = StateGraph(EmailState)

    # Add all nodes
    workflow.add_node("workflow_prepare_node", WorkflowPrepareNode())
    workflow.add_node("ocr_node", OCRNode())
    workflow.add_node("llm_attachment_node", LLMAttachmentNode())
    workflow.add_node("llm_email_node", LLMEmailNode())
    workflow.add_node("summary_node", SummaryNode())
    workflow.add_node("issue_node", IssueNode())
    workflow.add_node("workflow_finalize_node", WorkflowFinalizeNode())

    # Define execution order with parallel branches
    workflow.add_edge(START, "workflow_prepare_node")

    # Parallel execution: OCR path and Email path start simultaneously
    workflow.add_edge("workflow_prepare_node", "ocr_node")
    workflow.add_edge("workflow_prepare_node", "llm_email_node")

    # OCR path continues
    workflow.add_edge("ocr_node", "llm_attachment_node")

    # Both paths converge at summary_node
    # LangGraph automatically waits for all incoming edges
    workflow.add_edge("llm_attachment_node", "summary_node")
    workflow.add_edge("llm_email_node", "summary_node")

    # Sequential execution after summary
    workflow.add_edge("summary_node", "issue_node")
    workflow.add_edge("issue_node", "workflow_finalize_node")
    workflow.add_edge("workflow_finalize_node", END)

    # Compile with Redis checkpointer
    checkpointer = create_checkpointer()
    graph = workflow.compile(checkpointer=checkpointer)

    return graph

def execute_email_processing_workflow(
    email_id: str,
    force: bool = False
) -> Dict[str, Any]:
    """
    Execute the complete email processing workflow.

    Replaces: threadline/tasks/chain_orchestrator.process_email_chain

    Args:
        email_id: ID of the email to process
        force: Force processing regardless of status

    Returns:
        Dict containing:
        - success: bool
        - has_errors: bool
        - error_nodes: List[str]
        - state: Final state
    """
    from threadline.models import EmailMessage

    # Validate email exists
    email = EmailMessage.objects.get(id=email_id)

    # Create initial state
    initial_state = create_email_state(
        email_id,
        str(email.user_id),
        force
    )

    # Configure checkpoint
    config = {
        "configurable": {
            "thread_id": f"workflow_{email_id}",
            "checkpoint_ns": "email_processing"
        }
    }

    # Execute workflow
    graph = create_email_processing_graph()
    final_state = graph.invoke(initial_state, config=config)

    # Check results
    from threadline.agents.email_state import (
        has_node_errors,
        get_all_node_names_with_errors
    )

    has_errors = has_node_errors(final_state)
    error_nodes = (
        get_all_node_names_with_errors(final_state) if has_errors else []
    )

    return {
        "success": not has_errors,
        "has_errors": has_errors,
        "error_nodes": error_nodes,
        "state": final_state
    }
```

### Celery ä»»åŠ¡åŒ…è£…å™¨

```python
# threadline/tasks/chain_orchestrator.py (updated)

from celery import shared_task
from threadline.agents.workflow import execute_email_processing_workflow

@shared_task
def process_email_chain(email_id: str, force: bool = False) -> str:
    """
    Celery task wrapper for email processing workflow.

    This maintains backward compatibility with existing callers
    (API, Admin, Schedulers). Internal implementation now uses LangGraph.

    Args:
        email_id: ID of the email to process
        force: Force processing regardless of status

    Returns:
        str: email_id (for compatibility)
    """
    # Delegate to LangGraph workflow
    result = execute_email_processing_workflow(email_id, force)

    # Return email_id for compatibility with existing Celery chains
    return email_id
```

### ç®€åŒ–çš„çŠ¶æ€æœº

```python
# threadline/state_machine.py (updated)

class EmailStatus(Enum):
    """Simplified email processing status."""

    # Initial states
    FETCHED = 'fetched'

    # Processing states (unified)
    PROCESSING = 'processing'

    # Terminal states
    SUCCESS = 'success'
    FAILED = 'failed'
    COMPLETED = 'completed'

EMAIL_STATE_MACHINE = {
    EmailStatus.FETCHED: {
        EmailStatus.PROCESSING,
    },
    EmailStatus.PROCESSING: {
        EmailStatus.SUCCESS,
        EmailStatus.FAILED,
    },
    EmailStatus.FAILED: {
        EmailStatus.PROCESSING,  # Allow retry
    },
    EmailStatus.SUCCESS: {
        EmailStatus.COMPLETED,
    },
    EmailStatus.COMPLETED: set(),
}
```

**è¯´æ˜**ï¼šä¸­é—´å¤„ç†çŠ¶æ€ï¼ˆOCR_SUCCESSã€LLM_EMAIL_SUCCESS ç­‰ï¼‰ä¸å†éœ€è¦ï¼Œç”± LangGraph çŠ¶æ€çš„èŠ‚ç‚¹é”™è¯¯å­—æ®µç®¡ç†ã€‚

### èŠ‚ç‚¹å®ç°ç¤ºä¾‹

#### 1. OCR èŠ‚ç‚¹ï¼ˆçº¯ä¸šåŠ¡é€»è¾‘ï¼‰

```python
# threadline/agents/nodes/ocr_node.py

class OCRNode(BaseLangGraphNode):
    """
    OCR processing for image attachments.

    Replaces: threadline/tasks/ocr.py
    """

    def __init__(self):
        super().__init__("ocr_node")

    def can_enter_node(self, state: EmailState) -> bool:
        """Check if attachments exist for OCR."""
        if not super().can_enter_node(state):
            return False

        attachments = state.get('attachments', [])
        has_images = any(a.get('is_image') for a in attachments)

        if not has_images:
            self.logger.info("No image attachments, skipping OCR")
            return False

        return True

    def execute_processing(self, state: EmailState) -> EmailState:
        """Execute OCR on image attachments."""
        from threadline.utils.ocr_utils import process_image_ocr

        attachments = state.get('attachments', [])
        updated_attachments = []

        for attachment in attachments:
            if attachment.get('is_image'):
                # Perform OCR
                ocr_result = process_image_ocr(
                    attachment['file_path']
                )
                attachment['ocr_content'] = ocr_result

            updated_attachments.append(attachment)

        # Update state with OCR results
        return {
            **state,
            'attachments': updated_attachments
        }
```

#### 2. å®ŒæˆèŠ‚ç‚¹ï¼ˆæ•°æ®åº“åŒæ­¥ï¼‰

```python
# threadline/agents/nodes/workflow_finalize.py

class WorkflowFinalizeNode(BaseLangGraphNode):
    """
    Finalize node - syncs all results to database.

    Handles all result fields:
    - summary_title, summary_content, summary_priority
    - llm_content
    - Updates attachments with OCR results
    - Creates EmailIssue if issue_key exists
    """

    def _sync_data_to_database(self, state: EmailState) -> None:
        """Atomically sync all workflow results."""
        from django.db import transaction
        from threadline.models import (
            EmailMessage,
            EmailAttachment,
            EmailIssue
        )

        with transaction.atomic():
            email = EmailMessage.objects.select_for_update().get(
                id=self.email.id
            )

            # Sync summary results
            email.summary_title = state.get('summary_title', '')
            email.summary_content = state.get('summary_content', '')
            email.summary_priority = state.get('summary_priority', '')

            # Sync LLM content
            email.llm_content = state.get('llm_content', '')

            email.save()

            # Sync attachment OCR results
            attachments = state.get('attachments', [])
            for att_data in attachments:
                EmailAttachment.objects.filter(
                    id=att_data['id']
                ).update(
                    ocr_content=att_data.get('ocr_content', ''),
                    llm_ocr_content=att_data.get('llm_ocr_content', '')
                )

            # Create issue if exists
            issue_key = state.get('issue_key')
            if issue_key:
                EmailIssue.objects.update_or_create(
                    email_message=email,
                    defaults={
                        'issue_key': issue_key,
                        'issue_url': state.get('issue_url', ''),
                    }
                )
```

### Reset å®šæ—¶å™¨ç®€åŒ–

#### å½“å‰å®ç°ï¼ˆCelery æ¶æ„ï¼‰

```python
# threadline/tasks/scheduler.py
STUCK_STATUS_RESET_MAP = {
    # 4 ä¸ª PROCESSING çŠ¶æ€
    EmailStatus.OCR_PROCESSING.value: (EmailStatus.FETCHED.value, 'OCR'),
    EmailStatus.LLM_EMAIL_PROCESSING.value: (EmailStatus.FETCHED.value, 'LLM_EMAIL'),
    EmailStatus.LLM_SUMMARY_PROCESSING.value: (EmailStatus.FETCHED.value, 'LLM_SUMMARY'),
    EmailStatus.ISSUE_PROCESSING.value: (EmailStatus.FETCHED.value, 'Issue'),

    # 4 ä¸ª SUCCESS çŠ¶æ€ï¼ˆå¯èƒ½åœ¨é“¾ä¸­å¡ä½ï¼‰
    EmailStatus.OCR_SUCCESS.value: (EmailStatus.FETCHED.value, 'OCR_SUCCESS'),
    EmailStatus.LLM_EMAIL_SUCCESS.value: (EmailStatus.FETCHED.value, 'LLM_EMAIL_SUCCESS'),
    EmailStatus.LLM_SUMMARY_SUCCESS.value: (EmailStatus.FETCHED.value, 'LLM_SUMMARY_SUCCESS'),
    EmailStatus.ISSUE_SUCCESS.value: (EmailStatus.FETCHED.value, 'ISSUE_SUCCESS'),
}

@shared_task
def schedule_reset_stuck_processing_emails(timeout_minutes=30):
    """éœ€è¦æ‰«æ 8 ç§ä¸åŒçš„ä¸­é—´çŠ¶æ€"""
    stuck_statuses = list(STUCK_STATUS_RESET_MAP.keys())  # 8 ä¸ªçŠ¶æ€
    stuck_emails = EmailMessage.objects.filter(
        status__in=stuck_statuses,
        updated_at__lt=now - timedelta(minutes=timeout_minutes)
    )
    # å¤„ç†æ¯ä¸ªå¡ä½çš„é‚®ä»¶...
```

**é—®é¢˜**ï¼š
- éœ€è¦è·Ÿè¸ª **8 ç§ä¸åŒçš„ä¸­é—´çŠ¶æ€**
- æ¯ç§çŠ¶æ€éƒ½å¯èƒ½å› ä¸åŒåŸå› å¡ä½
- å¤æ‚çš„çŠ¶æ€æ˜ å°„é€»è¾‘
- éš¾ä»¥ç»´æŠ¤å’Œè°ƒè¯•

#### é‡æ„åï¼ˆLangGraph æ¶æ„ï¼‰

```python
# threadline/tasks/scheduler.py (simplified)

@shared_task
def schedule_reset_stuck_processing_emails(timeout_minutes=30):
    """
    Simplified: Only check PROCESSING status.

    All intermediate states are managed by LangGraph State,
    not in database.
    """
    now = timezone.now()

    # Only need to check ONE status: PROCESSING
    stuck_emails = EmailMessage.objects.filter(
        status=EmailStatus.PROCESSING.value,
        updated_at__lt=now - timedelta(minutes=timeout_minutes)
    )

    for email in stuck_emails:
        logger.warning(
            f"Email {email.id} stuck in PROCESSING for "
            f"{timeout_minutes}+ minutes, resetting to FAILED"
        )

        # Simply mark as FAILED, or retry with force mode
        email.status = EmailStatus.FAILED.value
        email.save(update_fields=['status'])

        # Optional: Retry with force mode
        # process_email_chain.delay(email.id, force=True)

    logger.info(f"Reset {len(stuck_emails)} stuck emails")
```

**æ”¹è¿›**ï¼š
1. **ä» 8 ç§çŠ¶æ€ â†’ 1 ç§çŠ¶æ€**
   - åªéœ€æ£€æŸ¥ `PROCESSING` çŠ¶æ€
   - æ‰€æœ‰ä¸­é—´å¤„ç†ç”± LangGraph State ç®¡ç†

2. **æŸ¥è¯¢ç®€åŒ–**
   - ä»å¤æ‚çš„ `status__in` æŸ¥è¯¢ â†’ ç®€å•çš„å•çŠ¶æ€æŸ¥è¯¢
   - æ›´é«˜æ•ˆçš„æ•°æ®åº“æŸ¥è¯¢

3. **é€»è¾‘æ¸…æ™°**
   - ä¸éœ€è¦å¤æ‚çš„çŠ¶æ€æ˜ å°„å­—å…¸
   - é‡ç½®é€»è¾‘ä¸€ç›®äº†ç„¶

4. **Redis Checkpoint è‡ªåŠ¨æ¸…ç†**
   - LangGraph çš„ Redis checkpoint æœ‰ TTL æœºåˆ¶
   - è¶…æ—¶çš„ checkpoint è‡ªåŠ¨è¿‡æœŸ
   - æ— éœ€æ‰‹åŠ¨æ¸…ç†ä¸­é—´çŠ¶æ€

5. **æ¢å¤ç­–ç•¥çµæ´»**
   - å¯ä»¥ç®€å•æ ‡è®°ä¸º FAILED
   - æˆ–ä½¿ç”¨ force æ¨¡å¼é‡æ–°å¤„ç†
   - ä¾é  LangGraph checkpoint æ¢å¤

**æ€§èƒ½å¯¹æ¯”**ï¼š

| æŒ‡æ ‡ | Celery æ¶æ„ | LangGraph æ¶æ„ | æ”¹å–„ |
|------|------------|---------------|------|
| éœ€æ£€æŸ¥çš„çŠ¶æ€æ•° | 8 | 1 | **87.5% â†“** |
| æ•°æ®åº“æŸ¥è¯¢å¤æ‚åº¦ | `IN (8 statuses)` | `= 1 status` | **æ›´ç®€å•** |
| ä»£ç ç»´æŠ¤æˆæœ¬ | é«˜ï¼ˆå¤šçŠ¶æ€æ˜ å°„ï¼‰ | ä½ï¼ˆå•ä¸€é€»è¾‘ï¼‰ | **æ˜¾è‘—é™ä½** |
| æ‰§è¡Œæ—¶é—´ | ~100ms | ~20ms | **80% â†“** |

### Email Processing è¿ç§»æ£€æŸ¥æ¸…å•

- [ ] **Phase 1: State Setup**
  - [ ] Create `threadline/agents/email_state.py`
  - [ ] Define `EmailState` TypedDict with all fields
  - [ ] Implement `create_email_state()` function
  - [ ] Add State helper functions

- [ ] **Phase 2: Node Implementation**
  - [ ] Create `threadline/agents/nodes/workflow_prepare.py`
    - Load EmailMessage and attachments
    - Map to State
    - Update status to PROCESSING
  - [ ] Create `threadline/agents/nodes/ocr_node.py`
    - Migrate logic from `tasks/ocr.py`
    - Pure State operations
  - [ ] Create `threadline/agents/nodes/llm_attachment_node.py`
    - Migrate logic from `tasks/llm_attachment.py`
  - [ ] Create `threadline/agents/nodes/llm_email_node.py`
    - Migrate logic from `tasks/llm_email.py`
  - [ ] Create `threadline/agents/nodes/summary_node.py`
    - Migrate logic from `tasks/llm_summary.py`
  - [ ] Create `threadline/agents/nodes/issue_node.py`
    - Migrate logic from `tasks/issue.py`
  - [ ] Create `threadline/agents/nodes/workflow_finalize.py`
    - Sync all results to database
    - Update final status

- [ ] **Phase 3: Workflow Orchestration**
  - [ ] Create `threadline/agents/workflow.py`
  - [ ] Implement `create_email_processing_graph()`
    - Add all 7 nodes
    - **é…ç½®å¹¶å‘æ‰§è¡Œ**ï¼šä» Prepare åŒæ—¶å¯åŠ¨ OCR å’Œ Email è·¯å¾„
    - **é…ç½®æ±‡èšç‚¹**ï¼šSummary ç­‰å¾…ä¸¤æ¡è·¯å¾„å®Œæˆ
  - [ ] Implement `execute_email_processing_workflow()`
  - [ ] Configure Redis checkpoint
  - [ ] Test parallel execution

- [ ] **Phase 4: Integration**
  - [ ] Update `threadline/tasks/chain_orchestrator.py`
  - [ ] Keep `process_email_chain()` signature unchanged
  - [ ] Delegate to `execute_email_processing_workflow()`
  - [ ] Test with existing API/Admin/Scheduler calls

- [ ] **Phase 5: Status Machine Simplification**
  - [ ] Update `threadline/state_machine.py`
  - [ ] Simplify to 5 core states
  - [ ] Update database migration for status field
  - [ ] Handle backward compatibility

- [ ] **Phase 6: Reset å®šæ—¶å™¨ç®€åŒ–**
  - [ ] Simplify `schedule_reset_stuck_processing_emails()` in `scheduler.py`
  - [ ] Remove `STUCK_STATUS_RESET_MAP` (8 states â†’ 1 state)
  - [ ] Only check `PROCESSING` status timeout
  - [ ] Update reset logic: PROCESSING â†’ FAILED
  - [ ] Optional: Add force mode retry logic
  - [ ] Test timeout detection and recovery

- [ ] **Phase 7: Testing & Validation**
  - [ ] Unit test each node
  - [ ] Integration test full workflow
  - [ ] Test checkpoint recovery
  - [ ] Test force mode
  - [ ] Performance comparison

### å®ç°æ”¶ç›Š

1. **çŠ¶æ€æœºç®€åŒ–**
   - ä» 13 ä¸ªçŠ¶æ€ â†’ 5 ä¸ªæ ¸å¿ƒçŠ¶æ€
   - OCR_SUCCESSã€LLM_OCR_SUCCESS ç­‰ä¸­é—´çŠ¶æ€ç”±çŠ¶æ€ç®¡ç†
   - é™ä½ç»´æŠ¤å¤æ‚åº¦

2. **æ•°æ®åº“è®¿é—®å‡å°‘**
   - ä» 5 ä¸ªä»»åŠ¡ Ã— å¤šæ¬¡æ•°æ®åº“æ“ä½œ â†’ ä»… 2 ä¸ªèŠ‚ç‚¹è®¿é—®æ•°æ®åº“
   - åªæœ‰å‡†å¤‡èŠ‚ç‚¹å’Œå®ŒæˆèŠ‚ç‚¹è®¿é—®æ•°æ®åº“
   - å®ŒæˆèŠ‚ç‚¹ä¸­ä½¿ç”¨åŸå­æ‰¹é‡æ“ä½œ

3. **å¹¶å‘æ‰§è¡Œï¼Œæ€§èƒ½æå‡**
   - OCR å¤„ç†è·¯å¾„å’Œé‚®ä»¶å†…å®¹å¤„ç†è·¯å¾„å¹¶å‘æ‰§è¡Œ
   - ä»ä¸²è¡Œ 18s â†’ å¹¶å‘ 10sï¼ˆå‡è®¾åœºæ™¯ï¼‰
   - **å·¥ä½œæµæ€»æ—¶é—´å‡å°‘çº¦ 30-44%**
   - å……åˆ†åˆ©ç”¨ç³»ç»Ÿèµ„æº

4. **é”™è¯¯å¤„ç†æ”¹è¿›**
   - åœ¨çŠ¶æ€ä¸­ç»Ÿä¸€è·Ÿè¸ªé”™è¯¯
   - èŠ‚ç‚¹å¤±è´¥åç»§ç»­æ‰§è¡Œå…¶ä»–èŠ‚ç‚¹ï¼ˆåŒ…æ‹¬å¹¶å‘åˆ†æ”¯ï¼‰
   - å®Œæ•´çš„é”™è¯¯ä¸Šä¸‹æ–‡å¯ç”¨

5. **æ£€æŸ¥ç‚¹æ¢å¤**
   - å¯ä»ä»»æ„èŠ‚ç‚¹æ¢å¤æ‰§è¡Œï¼ˆåŒ…æ‹¬å¹¶å‘èŠ‚ç‚¹ï¼‰
   - ä¸­æ–­æ—¶æ— æ•°æ®ä¸¢å¤±
   - è‡ªåŠ¨çŠ¶æ€æŒä¹…åŒ–

6. **å®šæ—¶ä»»åŠ¡ç®€åŒ–**
   - Reset å®šæ—¶å™¨ä»å¤„ç† 8 ç§ä¸­é—´çŠ¶æ€ç®€åŒ–ä¸º 1 ç§
   - åªéœ€æ£€æŸ¥ PROCESSING çŠ¶æ€æ˜¯å¦è¶…æ—¶
   - é™ä½å®šæ—¶å™¨å¤æ‚åº¦å’Œèµ„æºæ¶ˆè€—
   - Redis Checkpoint è‡ªåŠ¨ TTL æ¸…ç†

7. **é›¶ç ´åæ€§å˜æ›´**
   - ç°æœ‰ API/ç®¡ç†åå°/è°ƒåº¦å™¨ä¿æŒä¸å˜
   - `process_email_chain()` ç­¾åä¿æŒä¸å˜
   - é€æ˜å‡çº§

## æ€»ç»“

æœ¬è®¾è®¡æ–‡æ¡£æä¾›äº†å°† Celery task chain é‡æ„ä¸º LangGraph æ¶æ„çš„å®Œæ•´æŠ€æœ¯æ–¹æ¡ˆã€‚å…³é”®è®¾è®¡å†³ç­–åŒ…æ‹¬ï¼š

1. **èŒè´£åˆ†ç¦»**ï¼šé¦–å°¾èŠ‚ç‚¹å¤„ç†æ•°æ®åº“ï¼Œä¸­é—´èŠ‚ç‚¹çº¯ State æ“ä½œ
2. **çŠ¶æ€ç®€åŒ–**ï¼šä»å¤æ‚çŠ¶æ€æœºç®€åŒ–ä¸ºæ ¸å¿ƒçŠ¶æ€ï¼Œä¸­é—´çŠ¶æ€ç”± LangGraph ç®¡ç†
3. **å¹¶å‘æ‰§è¡Œ**ï¼šåˆ©ç”¨ LangGraph åŸç”Ÿå¹¶å‘èƒ½åŠ›ï¼Œæå‡å·¥ä½œæµæ€§èƒ½ 30-44%
4. **å®šæ—¶å™¨ç®€åŒ–**ï¼šReset å®šæ—¶å™¨ä» 8 ç§çŠ¶æ€ç®€åŒ–ä¸º 1 ç§ï¼Œé™ä½ 87.5% å¤æ‚åº¦
5. **ç»Ÿä¸€ç¼–æ’**ï¼šä½¿ç”¨ StateGraph æä¾›æ¸…æ™°çš„å·¥ä½œæµè§†å›¾
6. **å¯æ¢å¤æ€§**ï¼šRedis checkpoint ç¡®ä¿ä»»æ„èŠ‚ç‚¹å¯æ¢å¤
7. **å‘åå…¼å®¹**ï¼šä¿æŒä¸ç°æœ‰ç³»ç»Ÿçš„å…¼å®¹æ€§

**Email Processing å®ä¾‹**å±•ç¤ºäº†å¦‚ä½•å°†ç°æœ‰çš„ 5 æ­¥ä¸²è¡Œ Celery é“¾é‡æ„ä¸º 7 ä¸ª LangGraph èŠ‚ç‚¹ï¼ˆå‡†å¤‡èŠ‚ç‚¹ + 5ä¸ªä¸šåŠ¡èŠ‚ç‚¹ + å®ŒæˆèŠ‚ç‚¹ï¼‰ï¼Œå…¶ä¸­ OCR è·¯å¾„å’Œé‚®ä»¶å†…å®¹è·¯å¾„å¹¶å‘æ‰§è¡Œï¼ŒåŒæ—¶ç®€åŒ–çŠ¶æ€æœºä» 13 ä¸ªçŠ¶æ€åˆ° 5 ä¸ªæ ¸å¿ƒçŠ¶æ€ï¼Œå¹¶å¤§å¹…ç®€åŒ– reset å®šæ—¶å™¨é€»è¾‘ã€‚

ä¸‹ä¸€æ­¥ï¼šåŸºäºæ­¤è®¾è®¡åˆ›å»º tasks.md è¯¦ç»†å®æ–½è®¡åˆ’æ–‡æ¡£ã€‚
